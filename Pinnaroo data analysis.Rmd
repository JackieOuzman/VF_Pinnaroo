---
title: "Pinnaroo analysis"
author: "Jackie Ouzman"
date: "04/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r lib, include=FALSE}
library(dplyr)
library(tidyverse)
library(readr)
library(lubridate)
library(DT)
library(sp)


library(rgdal)
library(sf)

#install.packages("plotKML")
library(plotKML)
library(knitr)
library(png)

library(readxl)


library(ggmap)
library(maps)
library(mapdata)

library(raster)
#library(hms) Add these before I use them?
#library(plyr)
```

## Location of the trial

Block boundaries drawn in Google earth.



**Aim of trial:**

Selective grazing to barley paddock.
The aim was to evenly graze the frost effected part of the paddock.

Start date: 07/10/2021 3:59:00 PM (record not sure if it is local time)

End date: 20/10/2021 8:54:00 AM (deactivation record not sure if it is local time)

Number of animals: 40 (including one bull)

Date of fence move according to Rick records:



| vp_name	        | boundary_id| boundary_created	| activation_name                        |
| ----------------| -----------|----------------   |----------------------------------------|
| VP01 (Training)	| 2557	     | 7/10/2021 3:59 PM | Oct-07-1629-ACTIVATION-VP01 (Training) |
| VP02	          | 2556       |	11/10/2021 12:23 PM |	Oct-11-1253-ACTIVATION-VP02         |
| VP03            |	0853       |	12/10/2021 8:53 AM  |	Oct-12-0853-ACTIVATION-VP03         |
| VP03 with backgraze|1527     |	14/10/2021 2:57 PM  |	Oct-14-1527-ACTIVATION-VP03 with Backgraze|
| VP03-2 Final    |	1801       |	14/10/2021 5:31 PM | Oct-14-1801-ACTIVATION-VP03-2 Final |
| VP03-2 Final    |	1035       |	15/10/2021 10:05 AM| Oct-15-1035-ACTIVATION-VP03-2 Final |
| VP03-2 Final    |	1520       |	15/10/2021 2:50 PM | Oct-15-1520-ACTIVATION-VP03-2 Final |
| VP04-1 Move     | 0927       |	17/10/2021 9:27 AM | Oct-17-0927-ACTIVATION-VP04-1 Move  |

Some of these fences seem to be almost the same.



The location of the VF were supplied by Gallagher:

| vp_name	        | boundary_id| boundary_created| activation_name                          |
| ----------------| -----------|---------------- |----------------------------------------  |
| VP01 (Training)	| 2557	     | 	7/10/2021 5:11 | Oct-07-1629-ACTIVATION-VP01 (Training)   |
| VP02	          | 2556	     | 	7/10/2021 5:11 | Oct-11-1253-ACTIVATION-VP02              |
| VP03           	| 2561	     | 	7/10/2021 5:19 | Oct-12-0853-ACTIVATION-VP03              |
| VP03-2 Final    | 2590	     | 	14/10/2021 6:59| Oct-14-1801-ACTIVATION-VP03-2 Final      |
| VP03-2 Final    | 2590	     | 	14/10/2021 6:59| Oct-15-1035-ACTIVATION-VP03-2 Final      |
| VP03-2 Final    | 2590	     | 	14/10/2021 6:59| Oct-15-1520-ACTIVATION-VP03-2 Final      |
| VP04-1 Move	    | 2584	     | 	14/10/2021 4:40| Oct-17-0927-ACTIVATION-VP04-1 Move       |



This looks like an error with date and time.
I have emailed Gallagher to confirm.
Also requesting if they have a file to convert the different bounadry_id.

I have also asked for the water tank information.
Rick has given me two collar number:

0491508
0490705


I don't have any records of these collar or any extra collar data that is not already assigned to an animal.


I have used 

- VP 01
- VP 02
- VP 03
- VP 04-1

```{r location of trial, echo=FALSE, message=FALSE, warning=FALSE}

include_graphics("W:/VF/Pinnaroo/activation_VF/VF_boundary_details.png")

```




# Biomass 

Biomass survey was taken using Crop Circle ACS-430 and Crop Circle Phenom (ACS-430 with DAS43X, Holland Scientific, Lincoln, NE, USA).

These were calibrated by field measures of biomass.
 

## Biomass field measures

Biomass measured were taken before and after the trial was run.

Dates: 06/10/2021 and 20/10/2021




```{r biomass pre and post_trial, echo=FALSE, message=FALSE, warning=FALSE}
pre_post_trial_biomass <- read.csv("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/extract_grid_pts_pre_trial.csv")
#select only the pre trial data pts.
#names(pre_post_trial_biomass)

biomass_ave_pre_post <- pre_post_trial_biomass %>% 
  group_by(timing) %>% 
  summarise(av_BM = mean(BM__kg___H, na.rm= FALSE ),
            st_dev = sd(BM__kg___H, na.rm= FALSE),
            count = n())

datatable(biomass_ave_pre_post,
          options = list(dom = 't'),#removes the search bar
          caption = 'Biomass measures kg /Ha.',
          rownames = FALSE,
          colnames = c('Timing', 'Av Biomass', 'St dev biomass', 'Count')) %>% 
  formatRound(c(2:3), 0)
```


# Biomass survey 

**Pre trial survey**

Crop circle and Phenom survey undertaken by Damian on 06/10/2021

**Post trial survey**

Crop circle and Phenom survey undertaken by Damian on 20/10/2021



**Raw data**

Pre Trial

- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Pre trial\raw_data`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Pre trial\raw_data`

Post Trial

- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Post trial\raw_data`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Post trial\raw_data`

Note the files are merged before kriging 

The Phenom the data is split into sensor 1 and 2.

We have only used sensor 1 for this analysis.

We have used NDVI, LAI and DIST, there are other signals / channels that can be use.

At Long Plains we didn't used DIST - perhaps we should?

**Rasters** 

CC Pre Trial 

- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Pre trial\CC_NDVI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Pre trial\CC_LAI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Pre trial\CC_DIST\Vesper`

CC Post Trial

- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Post trial\CC_post_trial_NDVI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Post trial\CC_post_trial_LAI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Post trial\CC_post_trial_DIST\Vesper`



Phenom Pre Trial

- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Pre trial\Phenom_Pre_NDVI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Pre trial\Phenom_Pre_LAI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Pre trial\Phenom_Pre_DIST\Vesper`

Phenom Post Trial

- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Post trial\Phenom_post_trial_NDVI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Post trial\Phenom_post_trial_LAI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Post trial\Phenom_post_trial_DIST\Vesper`



Data processing done by Jackie using the following settings:

- Block boundaries created in Google earth pro.

- Data cleaned and trimmed using PAT QGIS tools, standard default settings used


- Block grid of 2m pixel made

- Vesper used for kriging cleaned data

- Vesper setting include; block kriging with a block size of 10m

- Data in below map is displayed as quantile.




## Pre trial maps

```{r cc_and phenom pre_trial, echo=FALSE, message=FALSE, warning=FALSE}

include_graphics("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/Pre_trial_biomass.png")


```


## plot of biomass vs survey data pre trial

Linear model 




```{r pre_trial biomass vs biomass survey, echo=FALSE, message=FALSE, warning=FALSE}

pre_post_trial_biomass <- read.csv("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/extract_grid_pts_pre_trial.csv")
#select only the pre trial data pts.
#names(pre_post_trial_biomass)
#rename some clm this is the order that was extered when extrcated in Arcmap
pre_post_trial_biomass <- pre_post_trial_biomass %>% 
  rename(Survey_Phen_DIST = pre_trial_,
         Survey_Phen_LAI = pre_trial1,
         Survey_Phen_NDVI = pre_tria_1,
         Survey_CC_DIST = cc_all_Hig,
         Survey_CC_LAI = CC_HighDen,
         Survey_CC_NDVI = CC_HighD_1)


#### how does the biomass pre trial relate to the pre trial biomass survey data?
pre_trial_biomass <- pre_post_trial_biomass %>% 
  filter(timing == "pre_trial")


#let rearragne the data so I can do a facet wrap
pre_trial_biomass_long <- pre_trial_biomass %>% 
pivot_longer(cols = starts_with("Survey"),
             names_to = "survey_type",
             values_to = "value")

#pre_trial_biomass_long %>%  group_by(survey_type) %>%  summarise(count = n()) #22

#http://www.sthda.com/english/wiki/ggplot2-scatter-plots-quick-start-guide-r-software-and-data-visualization
# method : smoothing method to be used. Possible values are lm, glm, gam, loess, rlm.
# method = “loess”: This is the default value for small number of observations. It computes a smooth local regression. You can read more about loess using the R code ?loess.
# method =“lm”: It fits a linear model. Note that, it’s also possible to indicate the formula as formula = y ~ poly(x, 3) to specify a degree 3 polynomial.
# se : logical value. If TRUE, confidence interval is displayed around smooth.
# fullrange : logical value. If TRUE, the fit spans the full range of the plot
# level : level of confidence interval to use. Default value is 0.95

plot1 <- pre_trial_biomass_long %>%
  #filter(survey_type == "Survey_CC_NDVI") %>% 
  ggplot(aes(x = value  , y =  BM__kg___H)) +
  geom_point()+
  geom_smooth(mapping = aes(x = value  , y =  BM__kg___H,group = survey_type),
              method = lm, se = FALSE)+
  #geom_smooth(se = FALSE)+
  facet_wrap(.~survey_type, scales = "free_x")+
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90))+
  labs(
    x = paste0("survey data"),
    y = "biomass cuts kg / ha",
    title = "Pre trial data"
  )
plot1
```




## The fit of models biomass vs survey data pre trial




```{r pre_trial biomass vs biomass survey model fit1, echo=FALSE, message=FALSE, warning=FALSE}



#http://www.sthda.com/english/articles/40-regression-analysis/167-simple-linear-regression-in-r/
  
  

pre_trial_biomass_long_CC_NDVI_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_CC_NDVI")
pre_trial_biomass_long_CC_LAI_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_CC_LAI")
pre_trial_biomass_long_CC_DIST_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_CC_DIST")

pre_trial_biomass_long_Phen_NDVI_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_NDVI")
pre_trial_biomass_long_Phen_LAI_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_LAI")
pre_trial_biomass_long_Phen_DIST_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_DIST")



cor_pre_CC_NDVI <- cor(pre_trial_biomass_long_CC_NDVI_pre$value, 
                       pre_trial_biomass_long_CC_NDVI_pre$BM__kg___H)
cor_pre_CC_LAI <- cor(pre_trial_biomass_long_CC_LAI_pre$value, 
                      pre_trial_biomass_long_CC_LAI_pre$BM__kg___H)
cor_pre_CC_DIST <- cor(pre_trial_biomass_long_CC_DIST_pre$value, 
                       pre_trial_biomass_long_CC_DIST_pre$BM__kg___H) 

cor_pre_Phen_NDVI <- cor(pre_trial_biomass_long_Phen_NDVI_pre$value, 
                       pre_trial_biomass_long_Phen_NDVI_pre$BM__kg___H)
cor_pre_Phen_LAI <- cor(pre_trial_biomass_long_Phen_LAI_pre$value, 
                      pre_trial_biomass_long_Phen_LAI_pre$BM__kg___H)
cor_pre_Phen_DIST <- cor(pre_trial_biomass_long_Phen_DIST_pre$value, 
                       pre_trial_biomass_long_Phen_DIST_pre$BM__kg___H) 


#Make a table with the analysis correlation table

pre_trial_table <- data.frame(survey  = c("NDVI", "LAI", "DIST", "NDVI", "LAI", "DIST"),
                              survey_type  = c("Crop Circle", "Crop Circle", "Crop Circle", "Phenom","Phenom","Phenom" ),
                              correlation = c(cor_pre_CC_NDVI, cor_pre_CC_LAI, cor_pre_CC_DIST,cor_pre_Phen_NDVI, cor_pre_Phen_LAI, cor_pre_Phen_DIST ),
                              timing  = c("pre_trial", "pre_trial", "pre_trial", "pre_trial", "pre_trial", "pre_trial"))



model_pre_CC_NDVI <- summary(lm(BM__kg___H ~ value, 
                                data = pre_trial_biomass_long_CC_NDVI_pre))
model_pre_CC_LAI <- summary(lm(BM__kg___H ~ value, 
                               data = pre_trial_biomass_long_CC_LAI_pre))
model_pre_CC_DIST <- summary(lm(BM__kg___H ~ value, 
                                data = pre_trial_biomass_long_CC_DIST_pre))

model_pre_Phen_NDVI <- summary(lm(BM__kg___H ~ value, 
                                data = pre_trial_biomass_long_Phen_NDVI_pre))
model_pre_Phen_LAI <- summary(lm(BM__kg___H ~ value, 
                               data = pre_trial_biomass_long_Phen_LAI_pre))
model_pre_Phen_DIST <- summary(lm(BM__kg___H ~ value, 
                                data = pre_trial_biomass_long_Phen_DIST_pre))

# model_pre_CC_NDVI
# model_pre_CC_NDVI$coefficients[1,1] #b0 Intercept
# model_pre_CC_NDVI$coefficients[2,1] #b1 slope
# model_pre_CC_NDVI$sigma #(Residual Standard Error from Linear Regression Model)
# model_pre_CC_NDVI$adj.r.squared
# model_pre_CC_NDVI$r.squared

#add this info to the pre_trial_table

pre_trial_model_table <- data.frame(survey  = c("NDVI", "LAI", "DIST", "NDVI", "LAI", "DIST"),
                                    survey_type  = c("Crop Circle", "Crop Circle", "Crop Circle", "Phenom","Phenom","Phenom" ),
                                    
                                    Intercept = c(model_pre_CC_NDVI$coefficients[1,1], model_pre_CC_LAI$coefficients[1,1], model_pre_CC_DIST$coefficients[1,1],
                                                  model_pre_Phen_NDVI$coefficients[1,1], model_pre_Phen_LAI$coefficients[1,1], model_pre_Phen_DIST$coefficients[1,1]),
                                    
                                    Slope = c(model_pre_CC_NDVI$coefficients[2,1], model_pre_CC_LAI$coefficients[2,1], model_pre_CC_DIST$coefficients[2,1],
                                              model_pre_Phen_NDVI$coefficients[2,1], model_pre_Phen_LAI$coefficients[2,1], model_pre_Phen_DIST$coefficients[2,1]),
                                    
                                    RSE = c(model_pre_CC_NDVI$sigma, model_pre_CC_LAI$sigma, model_pre_CC_DIST$sigma,
                                            model_pre_Phen_NDVI$sigma, model_pre_Phen_LAI$sigma, model_pre_Phen_DIST$sigma),
                                    
                                    R_Square = c(model_pre_CC_NDVI$r.squared, model_pre_CC_LAI$r.squared, model_pre_CC_DIST$r.squared,
                                                 model_pre_Phen_NDVI$r.squared, model_pre_Phen_LAI$r.squared, model_pre_Phen_DIST$r.squared),
                                    
                                    Adj_R_Square = c(model_pre_CC_NDVI$adj.r.squared, model_pre_CC_LAI$adj.r.squared,model_pre_CC_DIST$adj.r.squared,
                                                     model_pre_Phen_NDVI$adj.r.squared, model_pre_Phen_LAI$adj.r.squared,model_pre_Phen_DIST$adj.r.squared)
)




pre_trial_model <- left_join(pre_trial_table, pre_trial_model_table)

pre_trial_model <- pre_trial_model[, c(4, 1, 2, 3, 5,6,7,8)]

datatable(pre_trial_model,
          options = list(dom = 't'),#removes the search bar
          caption = 'Details of the models.',
          rownames = FALSE)%>%
           formatRound(c(4,8), 2) %>% 
           formatRound(5:7, 0)

```


The Phenom DIST has the best correlations but the R2 is low 0.32.
With this data set I would be reluctant converting survey data to biomass in Kg per ha.

But I guess if you had to this would look like this:

`summary(lm( BM__kg___H~  value, data = pre_trial_biomass_long_Phen_DIST_pre))`


```{r pre_trial biomass vs biomass survey best model fit, echo=FALSE, message=FALSE, warning=FALSE}
pre_trial_biomass_long_Phen_DIST_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_DIST")

summary(lm( BM__kg___H~  value, data = pre_trial_biomass_long_Phen_DIST_pre))
```

### Best option for converting survey data to biomass in kg/ha -  PRE TRIAL

biomass = intercept + slope * survey

biomass = -22649.9 + 593.8 * Phenom Dist survey value










## Post trial maps

```{r cc_and phenom post_trial, echo=FALSE, message=FALSE, warning=FALSE}

include_graphics("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/Post_trial_biomass.png")


```


## Plot of biomass vs survey data post trial

```{r post_trial biomass vs biomass survey, echo=FALSE, message=FALSE, warning=FALSE}

pre_post_trial_biomass_all <-
  read.csv(
    "W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/extract_grid_pts_pre_trial_all.csv"
  )
#select only the pre trial data pts.

#select post trial data
post_trial_biomass <- pre_post_trial_biomass_all %>%
  dplyr::select(
    FID,
    timing,
    ID,
    Lat,
    Long,
    BM__kg___H,
    Post_CC_ND,
    Post_CC_LA,
    Post_CC_DI,
    Post_Ph_ND,
    Post_Ph_LA,
    Post_Ph_DI
  )


post_trial_biomass <- post_trial_biomass %>%
  rename(
    Survey_Phen_DIST = Post_Ph_DI,
    Survey_Phen_LAI = Post_Ph_LA,
    Survey_Phen_NDVI = Post_Ph_ND,
    Survey_CC_DIST = Post_CC_DI,
    Survey_CC_LAI = Post_CC_LA,
    Survey_CC_NDVI = Post_CC_ND
  )

post_trial_biomass <- post_trial_biomass %>%
  filter(timing == "post_trial")


#let rearragne the data so I can do a facet wrap
post_trial_biomass_long <- post_trial_biomass %>%
  pivot_longer(cols = starts_with("Survey"),
               names_to = "survey_type",
               values_to = "value")


#post_trial_biomass_long %>%  group_by(survey_type) %>%  summarise(count = n())



#http://www.sthda.com/english/wiki/ggplot2-scatter-plots-quick-start-guide-r-software-and-data-visualization
# method : smoothing method to be used. Possible values are lm, glm, gam, loess, rlm.
# method = “loess”: This is the default value for small number of observations. It computes a smooth local regression. You can read more about loess using the R code ?loess.
# method =“lm”: It fits a linear model. Note that, it’s also possible to indicate the formula as formula = y ~ poly(x, 3) to specify a degree 3 polynomial.
# se : logical value. If TRUE, confidence interval is displayed around smooth.
# fullrange : logical value. If TRUE, the fit spans the full range of the plot
# level : level of confidence interval to use. Default value is 0.95

plot2 <- post_trial_biomass_long %>%
  ggplot(aes(x = value  , y =  BM__kg___H)) +
  geom_point()+
  geom_smooth(mapping = aes(x = value  , y =  BM__kg___H,group = survey_type),
              method = lm, se = FALSE)+
  #geom_smooth(se = FALSE)+
  facet_wrap(.~survey_type, scales = "free_x")+
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90))+
  labs(
    x = paste0("survey data"),
    y = "biomass cuts kg / ha",
    title = "Post trial data"
  )
plot2

post_trial_biomass_long_CC_NDVI_post <- post_trial_biomass_long %>%
  filter(survey_type == "Survey_CC_NDVI")
post_trial_biomass_long_CC_LAI_post <- post_trial_biomass_long %>%
  filter(survey_type == "Survey_CC_LAI")
post_trial_biomass_long_CC_DIST_post <- post_trial_biomass_long %>%
  filter(survey_type == "Survey_CC_DIST")

post_trial_biomass_long_Phen_NDVI_post <-
  post_trial_biomass_long %>%
  filter(survey_type == "Survey_Phen_NDVI")
post_trial_biomass_long_Phen_LAI_post <-
  post_trial_biomass_long %>%
  filter(survey_type == "Survey_Phen_LAI")
post_trial_biomass_long_Phen_DIST_post <-
  post_trial_biomass_long %>%
  filter(survey_type == "Survey_Phen_DIST")



cor_post_CC_NDVI <- cor(
  post_trial_biomass_long_CC_NDVI_post$value,
  post_trial_biomass_long_CC_NDVI_post$BM__kg___H
)
cor_post_CC_LAI <- cor(
  post_trial_biomass_long_CC_LAI_post$value,
  post_trial_biomass_long_CC_LAI_post$BM__kg___H
)
cor_post_CC_DIST <- cor(
  post_trial_biomass_long_CC_DIST_post$value,
  post_trial_biomass_long_CC_DIST_post$BM__kg___H
)

cor_post_Phen_NDVI <-
  cor(
    post_trial_biomass_long_Phen_NDVI_post$value,
    post_trial_biomass_long_Phen_NDVI_post$BM__kg___H
  )
cor_post_Phen_LAI <-
  cor(
    post_trial_biomass_long_Phen_LAI_post$value,
    post_trial_biomass_long_Phen_LAI_post$BM__kg___H
  )
cor_post_Phen_DIST <-
  cor(
    post_trial_biomass_long_Phen_DIST_post$value,
    post_trial_biomass_long_Phen_DIST_post$BM__kg___H
  ) 


#Make a table with the analysis correlation table

post_trial_table <-
  data.frame(
    survey  = c("NDVI", "LAI", "DIST", "NDVI", "LAI", "DIST"),
    survey_type  = c(
      "Crop Circle",
      "Crop Circle",
      "Crop Circle",
      "Phenom",
      "Phenom",
      "Phenom"
    ),
    correlation = c(
      cor_post_CC_NDVI,
      cor_post_CC_LAI,
      cor_post_CC_DIST,
      cor_post_Phen_NDVI,
      cor_post_Phen_LAI,
      cor_post_Phen_DIST
    ),
    timing  = c(
      "post_trial",
      "post_trial",
      "post_trial",
      "post_trial",
      "post_trial",
      "post_trial"
    )
  )



model_post_CC_NDVI <- summary(lm(BM__kg___H ~ value,
                                 data = post_trial_biomass_long_CC_NDVI_post))
model_post_CC_LAI <- summary(lm(BM__kg___H ~ value,
                                data = post_trial_biomass_long_CC_LAI_post))
model_post_CC_DIST <- summary(lm(BM__kg___H ~ value,
                                 data = post_trial_biomass_long_CC_DIST_post))

model_post_Phen_NDVI <- summary(lm(BM__kg___H ~ value,
                                   data = post_trial_biomass_long_Phen_NDVI_post))
model_post_Phen_LAI <- summary(lm(BM__kg___H ~ value,
                                  data = post_trial_biomass_long_Phen_LAI_post))
model_post_Phen_DIST <- summary(lm(BM__kg___H ~ value,
                                   data = post_trial_biomass_long_Phen_DIST_post))

# model_post_CC_NDVI
# model_post_CC_NDVI$coefficients[1,1] #b0 Intercept
# model_post_CC_NDVI$coefficients[2,1] #b1 slope
# model_post_CC_NDVI$sigma #(Residual Standard Error from Linear Regression Model)
# model_post_CC_NDVI$adj.r.squared
# model_post_CC_NDVI$r.squared

#add this info to the post_trial_table

post_trial_model_table <-
  data.frame(
    survey  = c("NDVI", "LAI", "DIST", "NDVI", "LAI", "DIST"),
    survey_type  = c(
      "Crop Circle",
      "Crop Circle",
      "Crop Circle",
      "Phenom",
      "Phenom",
      "Phenom"
    ),
    
    Intercept = c(
      model_post_CC_NDVI$coefficients[1, 1],
      model_post_CC_LAI$coefficients[1, 1],
      model_post_CC_DIST$coefficients[1, 1],
      model_post_Phen_NDVI$coefficients[1, 1],
      model_post_Phen_LAI$coefficients[1, 1],
      model_post_Phen_DIST$coefficients[1, 1]
    ),
    
    Slope = c(
      model_post_CC_NDVI$coefficients[2, 1],
      model_post_CC_LAI$coefficients[2, 1],
      model_post_CC_DIST$coefficients[2, 1],
      model_post_Phen_NDVI$coefficients[2, 1],
      model_post_Phen_LAI$coefficients[2, 1],
      model_post_Phen_DIST$coefficients[2, 1]
    ),
    
    RSE = c(
      model_post_CC_NDVI$sigma,
      model_post_CC_LAI$sigma,
      model_post_CC_DIST$sigma,
      model_post_Phen_NDVI$sigma,
      model_post_Phen_LAI$sigma,
      model_post_Phen_DIST$sigma
    ),
    
    R_Square = c(
      model_post_CC_NDVI$r.squared,
      model_post_CC_LAI$r.squared,
      model_post_CC_DIST$r.squared,
      model_post_Phen_NDVI$r.squared,
      model_post_Phen_LAI$r.squared,
      model_post_Phen_DIST$r.squared
    ),
    
    Adj_R_Square = c(
      model_post_CC_NDVI$adj.r.squared,
      model_post_CC_LAI$adj.r.squared,
      model_post_CC_DIST$adj.r.squared,
      model_post_Phen_NDVI$adj.r.squared,
      model_post_Phen_LAI$adj.r.squared,
      model_post_Phen_DIST$adj.r.squared
    )
  )




post_trial_model <-
  left_join(post_trial_table, post_trial_model_table)

post_trial_model <- post_trial_model[, c(4, 1, 2, 3, 5, 6, 7, 8)]

datatable(
  post_trial_model,
  options = list(dom = 't'),
  #removes the search bar
  caption = 'Details of the models.',
  rownames = FALSE
) %>%
  formatRound(c(4, 8), 2) %>%
  formatRound(5:7, 0)


```

### Best option for converting survey data to biomass in kg/ha -  POST TRIAL

The Phenom DIST has the best correlations but the R2 is low 0.32.
With this data set I would be reluctant converting survey data to biomass in Kg per ha.

But I guess if you had to this would look like this:

`summary(lm( BM__kg___H~  value, data = pre_trial_biomass_long_Phen_DIST_pre))`


```{r post_trial biomass vs biomass survey best model fit, echo=FALSE, message=FALSE, warning=FALSE}
post_trial_biomass_long_Phen_DIST_pre <- post_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_DIST")

summary(lm( BM__kg___H~  value, data = post_trial_biomass_long_Phen_DIST_pre))
```



biomass = intercept + slope * survey

biomass = -23,519 + 609	 * Phenom Dist survey value






### Pre and post grids of biomass

Converted using the values and grids outlined above.

```{r phenom DIST converted to biomass pre post_trial, echo=FALSE, message=FALSE, warning=FALSE}

include_graphics("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/Pre Post_trial_biomass_DIST.png")


```

### Pre and post grids of biomass display the VF area only


```{r converted to biomass pre post_trial with VF, echo=FALSE, message=FALSE, warning=FALSE}

include_graphics("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/Pre Post_trial_biomass_DIST with VF.png")


```


### Notes / observation from the above maps.

- There is a big difference between the biomass pre and post trial.
- Pre trial within the VF there are patches of higher biomass long the hard fence line to the south,
especially in the south eastern corner.
- Also higher biomass in the north west corner.
- Although these relatively higher patches remain in the post trial biomass map.
- The difference map indicates that the patches of high biomass before the trial were the most grazed area of the paddock.
- Along the southern fence line a an area of the paddock the animals are unlikely to receive any cues, as the VF boundaries extend beyond the hard fence.
- Areas of light grazing of note is the small triangle on the northern VF between VF 1 and VF3. 

| Summary Stat for VF area (from .tif files)	        | 
| ------- | ----------|-------------|
| stat    |Pre trial  | Post trail	|
| Min     |3030       | 676	        |
| Max     |9215       | 5299        |	
| Mean    |59356      |2831         |	
| Std Dev |1029       |812	        | 




# Weeds data
samples collected 2/11/2021 (Damian)


```{r converted to biomass post_trial with VF and broome data, echo=FALSE, message=FALSE, warning=FALSE}

include_graphics("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/Broome sampling with VF.png")


```

### Notes / observation from the above maps.

- larger patches of Broome in VF 4 and outside VF area
- Brome patches are located in the southern area

- On averages the patches are smaller patches outside VF
- but same number of plants per patch inside and outside the VF

- More heads per viable/plant outside VF.

- less heads on ground and less brome plants on the ground outside VF.



| Summary Stat Brome samples 	        | 
| ------- | ----------|-------------|
| Stats                           |Inside VF  | Outside VF	|
| sum of size of all patches      |10.4       | 7.8	        |
| Average of size of patches      |2.1        | 1.6	        |
| count of patches                |5          | 5           |	
| Average plants per patch        |35         |35.6         |	
| Average HM heads are viable/plant |40.5     |46.8         |
| Average heads on ground         |22.2       |16.2         |
| Average brome plants on ground  |4.9       |0         |



- `W:\VF\Pinnaroo\Biomass_data_maps\Pre and Post trial biomass\Pinnaroo Pre_Post Biomass cuts.xlsx`




## Background information on animal collar data from Gallagher


**Contact**

The chief data scientist/ data analytics manager is:


Dr. Shiva Pratap Gopakumar | Data Scientist | eShepherd

Gallagher eShepherd Pty Ltd

1100-1102 Toorak Road, Camberwell, VIC, 3124

DDI +61 3 8849 8600 | MOB +61 426 092 143

EMAIL shiva.gopakumar@gallagher.com | WEB www.gallagher.com



**Data provided**


Every 10 mins generates a new row of data.

This can be viewed from the timeOfEvent column.

**timeOfEvent**

Note that this timeOfEvent has a date and time stamp which is in GMT.

The *timeOfEvent* will need to be converted to local time.

Which is 10.5 hrs difference 

(during daylight saving starts 3rd Oct - so this is correct for our dataset)

**GPS**

The GPS data is a snapshot of the location of the animals in a 10 min window.

Data columns that are supplied:

- *gpsData.lat*	
- *gpsData.lng*


I will use the lat and long column to create a location of the animal in the 10 min window.

The accuracy of this reading can be viewed within this 10 min window.


In other years we have calculated the velocity but I am not sure if we need this now and how would it work?

I am also not sure about the use of the velocity reading, how would this be calculated if only one GPS record was logged every 10mins? 


**Stimuli - cue and audio readings**

The *cumulativeAudioCount* and	*cumulativeShockCount* columns are a running total of how many stimuli the animal has received since the start of the trial, and is re calculated every 10 mins.

It appears that the increments are not reset when a new fence is implement.
Instead its just keeps cumulating.

**Device details**

The *deviceName* is the name of the collar, more details about the mob can be found on the shared drive.


- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Animal_wts\Usable animal weights.xlsx`
- tab merged_dataID_wts

There is another columns which has information about the device this is called *deviceUIDHex*.




**Virtual Fence**


There is a column which is called *minDistanceToIZ*, which is the distance of the animal to the VF.

I am not sure if this is the min distance the animal got to the fence in the 10 min window or its the distance calculated from the logged GPS point in the file in the 10 mins window.

If it is the min distance the animal got to and not just the distance from the fence in the 'snap shot' this would be useful.

Column called *fencesID* is the name of the fence.




       

If the *fencesID* is NULL then the *minDistanceToIZ* is also NULL.

If the *fencesID* is blank then the *minDistanceToIZ* is also NULL or has a value there are only 2 of these.


*"If the values in “fenceID” column as blank, this means there is no active virtual fence for that neckband yet. Therefore, if you are performing some analysis related to virtual fencing, you can ignore those rows with blank fenceIDs."*


**Animal activity**

There are 3 columns that relate to the 

- *resting%*	

- *moving%*

- *grazing%* 



The first 3 should add up to 100% and this is a sum value for the 10 min of time.

For example in the 10 min window the animals has spent 37% of the time resting, 30% moving and 33% grazing.









# Data manipulation 


## Step 1 bring in the raw data and set date and time formats


**Add date column**

- this is has no rounding and is just the date extracted from the local time column

**retain data within a date and time range**

- I have also filter out data within a date and time range (I have got this from Rick notes)

- between "2021-10-07 16:03:00" to "2020-10-20 08:54:00" localtime 











```{r bring in the data, message=TRUE, include=FALSE}

animal_GPS_data <- read_csv("W:/VF/Pinnaroo/animal behaviour data/raw_data/CSIRO_Pinnaroo.csv", 
                                              col_types = cols(timeOfEvent = col_datetime(format = "%d/%m/%Y %H:%M")))

animal_GPS_data <- animal_GPS_data %>% 
  mutate(GMT = ymd_hms(timeOfEvent, tz = "GMT"))

animal_GPS_data <- animal_GPS_data %>% 
  mutate(local_time = with_tz(GMT, tz = "Australia/Adelaide"))

animal_GPS_data <- animal_GPS_data %>% 
  dplyr::select(deviceUIDHex:grazing_percentage, GMT:local_time)

animal_GPS_data <- animal_GPS_data %>%  filter(local_time >= ymd_hms("2021-10-07 16:03:00", tz= "Australia/Adelaide"), 
                         local_time <=  ymd_hms("2021-10-20 08:54:00", tz= "Australia/Adelaide"))

animal_GPS_data <- animal_GPS_data %>% 
  mutate(date = as.Date(local_time, tz= "Australia/Adelaide"),
         DOY = yday(date))



```

**Column for VF area**

- Create a column that will help identify what part of the paddock the cows are allowed to graze in.

- Gallagher will confirm the fenceID in the animal movement file and the fenceID boundary file (as they have different codes) 

- The animal movement data has an clm with 'fence ID', so when a VF is active this clm will have the fence ID value in it.

- There is a problem with some logged points, the fence ID clm is blank.
- I assume this is happening because the VF is deactivated.
- Gallagher suggested "For the VF dataset only retaining data points that have an associated fence ID".




- The list below is the dates and times for the fences ID in the animal movement files.


```{r fence ID date and time, echo=FALSE}

check2 <- animal_GPS_data %>% group_by(  fencesID) %>% 
  summarise(min_local_time = ymd_hms(min(local_time), tz= "Australia/Adelaide"),
            max_local_time = ymd_hms(max(local_time), tz= "Australia/Adelaide"),
            count_records = n())
check2 <- arrange(check2, min_local_time)

check2

# the DT table seems to use some strange time setting not sure what the work around is other than date only as below
# DT::datatable(
#   check2,
#   options = list(dom = 't'),
#   #removes the search bar
#   caption = 'Details of the fence ID.',
#   rownames = FALSE
# ) %>% 
#   formatDate(c(2,3), method = 'toDateString')


```

- the fenceID (from the animal movement file) need to be matched up with the VF area (the spatial data)




*This needs confirming and if needs changing the code below need work*


| fence ID in GPS data 	                | 
| ----------          |-------------    |
|   ID in GPS data    | ID for mapping	|
|   165 +02           | 	VP01          |
|   165               | 	VP01          |
|   1f6da             |   VF02          |
|   1d10b             | 	VP03          |
|   1f076             | 	VP03_2        |
|   1ab95             | 	VP03_2        |
|   1df99             | 	VF04          |
|   NULL              | 	?             |



**Add Day since start of VF columns** 



- Add extra one for days since fence move clm called 'day_since_vf_start'

- Julian days from local date/time column and then subtract start of VF.


VF Area 1 = date 2021-10-07 16:03:00
VF Area 2 = date 2021-10-11 12:33:00
VF Area 3 = date 2021-10-12 09:03:00 (this is a few fences all named VF3 )
VF Area 4 = date 2021-10-17 09:33:00


```{r add clms days since start, echo=FALSE, message=FALSE, warning=FALSE}

## clm for day of year in local time

vf1_area_start  <-  yday(ymd_hms("2021-10-07 16:03:00", tz= "Australia/Adelaide")) 
vf2_area_start  <-  yday(ymd_hms("2021-10-11 12:33:00", tz= "Australia/Adelaide"))
vf3_area_start  <-  yday(ymd_hms("2021-10-12 09:03:00", tz= "Australia/Adelaide"))
vf4_area_start  <-  yday(ymd_hms("2021-10-17 09:33:00", tz= "Australia/Adelaide"))


animal_GPS_data <- animal_GPS_data %>%  
  mutate(
    VF_area  = case_when(
      fencesID == "1.65E+02" ~ "VF_area1",
      fencesID == "165" ~ "VF_area1",
      
      fencesID == "1f6da" ~ "VF_area2",
      
      fencesID == "1d10b" ~ "VF_area3",
      fencesID == "1f076" ~ "VF_area3",
      fencesID == "1ab95" ~ "VF_area3",
      
      fencesID == "1df99" ~ "VF_area4"))


animal_GPS_data <- animal_GPS_data %>%  
  mutate(
    day_since_vf_start  = case_when(
      VF_area == "VF_area1" ~ (DOY-vf1_area_start)+1,
      
      VF_area == "VF_area2" ~ (DOY-vf2_area_start)+1,
      
      VF_area == "VF_area3" ~ (DOY-vf3_area_start)+1,
      
      VF_area == "VF_area4" ~ (DOY-vf4_area_start)+1))
  

check3 <- animal_GPS_data %>% group_by( VF_area) %>% 
  summarise('min day since VF move' = min(day_since_vf_start),
            'max day since VF move' = max(day_since_vf_start))

check3
```




## Plot stimuli results



- The stimuli data is supplied as a 'cumulative value'.
- I would like it to be plotted per day and fence.

- I could report the cumulative audio pulses and cumulative pulse pulses for the same time each day of the trial.
- and then do some work to remove the previous days reading.

*reducing data to only have reading per day per animal at 3pm for cue data*

- Sub-setting the data only retaining values at 5pm for each day.

- But we don't always have readings for 5pm.
- I have rounded the time column to the closest 15mins
- I can pull out a window and use that e.g. 17:00 - 17:15.



- Using a 3pm window to subset the data, I double check that I have readings for all animals.
- Some animals have 2 readings while others have only 1.
- So I can't change this window too much (as I need a at least 1 record, looks good). 



Grouping the 3pm window data on date and collar ID.
Summary stats on the min values for each day per animal:

- a = audio min value per day per animal
- b = pulse min value per day per animal
- ratio =  ((b/a)*100) per day per animal


Note that these are still cummulative readings (but just for the 3pm window)

```{r working -ratio , message=FALSE, warning=FALSE, include=FALSE}

#1 create an ID for each row
test <- animal_GPS_data
test$ID <- seq.int(nrow(test))



# create a new clm that rounds the time to every 15 mins
test_VF_for_5pm <- test %>% 
  mutate(round_date_time = ceiling_date(local_time, "15 mins"),
         time_round = hms::as_hms(round_date_time))


#value at the start of each day pull out the values for this window
test_VF_for_5pm <- test_VF_for_5pm %>% 
  filter(time_round >= hms::as_hms('17:00:00'),
         time_round <= hms::as_hms('17:15:00'))

ungroup(test_VF_for_5pm)


str(test_VF_for_5pm)
# what is the smallest values in the data set for each animal and day
test_VF_for_5pm <- test_VF_for_5pm %>% 
  group_by(deviceName, date) %>% 
  summarise(
    min_local_time = ymd_hms(min(local_time), tz= "Australia/Adelaide"),
    ID = ID)

test_VF_for_5pm <- test_VF_for_5pm %>% 
  group_by(deviceName, date) %>% 
  summarise(
    min_ID = (min(ID)))


#I think this is working now I need to use the ID to retain values in the first dataset.
# use a join to do this
ungroup(test_VF_for_5pm)
str(test_VF_for_5pm)
test_VF_for_5pm <- test_VF_for_5pm %>% 
  dplyr::select(min_ID)

join <- left_join(test_VF_for_5pm,test, by = c("min_ID" = "ID") )
str(join)

join <- join %>%  dplyr::rename(deviceName = deviceName.x) %>% 
  dplyr::select(-deviceName.y )


### how many animals and how many days? look like we have 39 collars for days 281 to 292
animal_count <- join %>% group_by(DOY) %>% 
  summarise(count = n())

```

```{r check 5pm data, echo=TRUE, message=FALSE, warning=FALSE}
animal_count

```

## Plot stimuli results per animal


```{r working for plots cues, echo=FALSE, message=FALSE, warning=FALSE}

five_pm_per_animal <- join %>% 
  group_by(date, deviceName) %>%
  summarise(audio = min( cumulativeAudioCount, na.rm = TRUE),
            pulse = min( cumulativeShockCount, na.rm = TRUE),
            ratio = (pulse/audio)*100)


five_pm_per_animal <- ungroup(  five_pm_per_animal)

# make df narrow


five_pm_per_animal <- pivot_longer(five_pm_per_animal,
                                             cols = c("audio", "pulse", "ratio"),
                                             names_to = "stimuli")




#plots



#str(week1_2_3_for_3pm_per_animal$date)

vertical_lines <- c("2021-10-07", "2021-10-11", "2021-10-12", "2021-10-17")

#str(vertical_lines)
```

```{r plots -audio, echo=FALSE, message=FALSE, warning=FALSE}
five_pm_per_animal %>%
  filter(stimuli == "audio" ) %>%
  ggplot(aes(x = date , y = value)) +
  geom_col()+
  theme_classic() +
  facet_wrap(.~deviceName)+
  theme(axis.text.x = element_text(angle = 90))+
  geom_vline(xintercept = as.Date(vertical_lines), col = "blue")+
  labs(
    x = "Date",
    y = "audio",
    title = paste("Cumulative reading reported 5pm every day of trial, per animal")
  )


```


*Notes / observation*

- This is each animal per day of trial, the cumulative audio readings at 5pm each day.
- The first fence was turnned on at 4pm (day 1 has about 1 hours worth of data).
- The last fence was turned off 20th 9am (so this series of graphs stop at 19th 5pm).

- Audio cues recieved is variable between animals
- Some animals have a steady increase over time trial, this means that they are constantly testing the fence.
- Some animals get no cues on day 1 and very few for the first few days.
- Some animals tested the fence at the start and then cues platue off, they didn't do much more testing.
- There does not seem to be an increase in audio cues when the fence is moved.
- How does that work? are some animals following what others are doing?

```{r plots -pulse, echo=FALSE, message=FALSE, warning=FALSE}
five_pm_per_animal %>%
  filter(stimuli == "pulse" ) %>%
  ggplot(aes(x = date , y = value)) +
  geom_col()+
  theme_classic() +
  facet_wrap(.~deviceName)+
  theme(axis.text.x = element_text(angle = 90))+
  geom_vline(xintercept = as.Date(vertical_lines), col = "blue")+
  labs(
    x = "Date",
    y = "pulse ",
    title = paste("Cumulative reading reported 5pm every day of trial, per animal")
  )


```

*Notes / observation*

- Similar to pulse data but with even less data


```{r plots -ratio, echo=FALSE, message=FALSE, warning=FALSE}
five_pm_per_animal %>%
  filter(stimuli == "ratio" ) %>%
  ggplot(aes(x = date , y = value)) +
  geom_col()+
  theme_classic() +
  facet_wrap(.~deviceName)+
  theme(axis.text.x = element_text(angle = 90))+
  geom_vline(xintercept = as.Date(vertical_lines), col = "blue")+
  labs(
    x = "Date",
    y = "ratio (pulse/audio)*100 ",
    title = paste("Cumulative reading reported 5pm every day of trial, per animal")
  )


```

*Notes / observation*

- Ratio plots are easier to compare the animals.
- Can't see the change in cues as a fence is moved.





## Plot of avearge stimuli for all animal per day (still cumulative data)

- I have grouped the data into date and calculated:
  
  
- mean of audio pulses for all the animals
- mean of pulse for all the animals
- mean of ratio for all the animals (note the ratio were first calulated per animal)



```{r results -stimuli for audio , echo=FALSE, message=FALSE, warning=FALSE}


five_pm_per_animal_summary_per_day <- five_pm_per_animal %>% 
  group_by(date, stimuli)%>%
  summarise(stimuli_av_day = mean(value, na.rm = TRUE))



five_pm_per_animal_summary_per_day %>%
  filter(stimuli == "audio" ) %>% 
  ggplot(aes(x = date , y = stimuli_av_day)) +
  geom_col()+
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90))+
  geom_vline(xintercept = as.Date(vertical_lines), col = "blue")+
  labs(
    x = "Date",
    y = "average audio of all animals",
    title = paste("")
  )


```


```{r results -stimuli for pulse , echo=FALSE, message=FALSE, warning=FALSE}


five_pm_per_animal_summary_per_day <- five_pm_per_animal %>% 
  group_by(date, stimuli)%>%
  summarise(stimuli_av_day = mean(value, na.rm = TRUE))



five_pm_per_animal_summary_per_day %>%
  filter(stimuli == "pulse" ) %>% 
  ggplot(aes(x = date , y = stimuli_av_day)) +
  geom_col()+
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90))+
  geom_vline(xintercept = as.Date(vertical_lines), col = "blue")+
  labs(
    x = "Date",
    y = "average pulse of all animals",
    title = paste("")
  )


```

```{r results -stimuli for ratio , echo=FALSE, message=FALSE, warning=FALSE}


five_pm_per_animal_summary_per_day <- five_pm_per_animal %>% 
  group_by(date, stimuli)%>%
  summarise(stimuli_av_day = mean(value, na.rm = TRUE))



five_pm_per_animal_summary_per_day %>%
  filter(stimuli == "ratio" ) %>% 
  ggplot(aes(x = date , y = stimuli_av_day)) +
  geom_col()+
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90))+
  geom_vline(xintercept = as.Date(vertical_lines), col = "blue")+
  labs(
    x = "Date",
    y = "average ratio of all animals",
    title = paste("")
  )


```




```{r results -stimuli for ratio no facet 1 , echo=FALSE, message=FALSE, warning=FALSE}

five_pm_per_animal_summary_per_day %>%
  filter(stimuli != "ratio" ) %>% 
  ggplot(aes(x = date , y = stimuli_av_day)) +
  geom_col(aes(fill = stimuli), width = 0.7)+
  theme_classic() +
  geom_vline(xintercept = as.Date(vertical_lines), col = "blue")+
  theme(axis.text.x = element_text(angle = 90))+
  labs(
    x = "Date",
    y = "Average of stimuli",
    title = paste("")
  )


five_pm_per_animal_summary_per_day_table <- five_pm_per_animal_summary_per_day %>% 
  filter(stimuli == "ratio" ) %>%
  group_by(date, stimuli)%>% 
  summarise(
    mean_stimuli = mean(stimuli_av_day   , na.rm =TRUE))
five_pm_per_animal_summary_per_day_table

```


## Total administered cues, at then of the trial

- below information is just for 20th seems it is cumulative.

```{r results -stimuli for ratio no facet  , echo=FALSE, message=FALSE, warning=FALSE}

per_animal <- animal_GPS_data %>% 
  group_by(date, deviceName) %>%
  summarise(audio = max( cumulativeAudioCount, na.rm = TRUE),
            pulse = max( cumulativeShockCount, na.rm = TRUE),
            ratio = (pulse/audio)*100)


per_animal <- ungroup(  per_animal)

# names(per_animal)
# str(per_animal)
per_animal_20th <- per_animal %>% 
  filter(date =="2021-10-20" )

per_animal_20th %>% 
  filter(stimuli == "audio"| stimuli == "pulse") %>% 
ggplot( aes(x=as.factor(stimuli), y=value)) + 
  geom_boxplot(fill="slateblue", alpha=0.2) + 
  xlab("stimuli")


summary_20th <- per_animal_20th %>% 
  group_by(stimuli) %>% 
  summarise(ave_cum_for_animals = mean(value, na.rm = TRUE),
            SD = sd(value, na.rm = TRUE),
            sum_cum_for_animals = sum(value, na.rm = TRUE))

summary_20th
```


## Plot activity results
 

These values are not cumulative.

Each data line (and associated time is independent from the time before).

However each line (row) is a summary of the animals activity in a 10 min window.


The below plots are created using two steps:
- Average per day per animals for the nominated activity.
- Then the average of all the animals per activity is calulated and plotted



**Per day plots**




```{r lying_standing , echo=FALSE, message=FALSE, warning=FALSE}



animal_GPS_data$resting_percentage <- as.double(animal_GPS_data$resting_percentage)
animal_GPS_data$moving_percentage    <- as.double(animal_GPS_data$moving_percentage)
animal_GPS_data$grazing_percentage   <- as.double(animal_GPS_data$grazing_percentage)



#for each day and animal ave time for activity
animal_GPS_data_av_activity_day <- animal_GPS_data %>% 
  group_by(date, deviceName) %>% 
  summarise(av_resting = mean( resting_percentage, na.rm = TRUE),
            av_moving = mean( moving_percentage, na.rm = TRUE),
            av_grazing = mean( grazing_percentage, na.rm = TRUE))



animal_GPS_data_av_activity_day <- pivot_longer(animal_GPS_data_av_activity_day,
                                                  cols = c("av_resting", "av_moving", "av_grazing"),
                                                  names_to = "activity")





animal_GPS_data_activity_1 <- animal_GPS_data_av_activity_day %>% 
  group_by(date, activity)%>%
  summarise(activity_av_day = mean(value, na.rm = TRUE))

#str(animal_GPS_data_activity_1)

animal_GPS_data_activity_1 %>%
  ggplot(aes(x = date , y = activity_av_day)) +
  geom_col(aes(fill = activity), width = 0.7)+
  theme_classic() +
  geom_vline(xintercept = as.Date(vertical_lines), col = "black")+
  theme(axis.text.x = element_text(angle = 90))+
  labs(
    x = "Date",
    y = "% time attributed to activity",
    title = paste("all animals")
  )


```


# Animal weights

```{r animal wts, echo=FALSE, message=FALSE, warning=FALSE}
animal_wts <- read_excel("W:/VF/Pinnaroo/Animal_wts/Usable animal weights.xlsx", sheet ="merged_dataID_wts" )



animal_wts <- animal_wts %>%
  dplyr::select(deviceUIDHex,
                deviceName,
                date_in = "Date weight in",
                date_out ="date weight out",
                wt_diff ="Weight difference")


animal_wts <- animal_wts %>%
  filter(!is.na(deviceName))
#animal_wts$date_out - animal_wts$date_in

animal_wts_stats <- animal_wts %>% 
  group_by() %>% 
  summarise(sum_wt_gain = sum(wt_diff, na.rm = TRUE),
            Av_wt_gain = mean(wt_diff, na.rm = TRUE),
            std_dev_wt_gain = sd(wt_diff, na.rm = TRUE),
            Av_wt_gain_per_day = (mean(wt_diff, na.rm = TRUE))/13,
            count = n()
  )


datatable(
  animal_wts_stats,
  options = list(dom = 't'),
  #removes the search bar
  caption = 'Weight gain kg',
  rownames = FALSE,
  colnames = c('Total for mob', 'Average per animal', 'Stdev per animal', 'Av per animal per day','Count') )%>%   
    formatRound(c(1:4), 2)

```


```{r animal wts plot, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(animal_wts, aes(as.factor(deviceName), wt_diff)) +
  geom_col()+
  theme_bw()+
  theme(axis.text.x=element_blank(),
  axis.ticks = element_blank())+
  labs(title="Animal weight gain after 13 days",
       x ="Animal", y = "Weight gain (kg)")
```
  
  
## Extra Notes
  
-  Track which animal spent time outside the VF and ID them, non compliant.
-  Compare early behaviour (the behaviour in the first couple of days) of these of these non compliant vs main herd.
-  The numbers should be approx 30/40 main herd, 10/40 or 6-7/40 were non compliant.
-  Note at time Heath re oriented these non compliant animals (back into the VF area).

-  Can we identify hotspots outside the VF area, if so do they match anything in the biomass data?
-  Exclude the Bull from the start.



  