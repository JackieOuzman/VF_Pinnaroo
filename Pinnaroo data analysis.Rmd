---
title: "Pinnaroo analysis"
author: "Jackie Ouzman"
date: "04/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r lib, include=FALSE}
library(dplyr)
library(tidyverse)
library(readr)
library(lubridate)
library(DT)
library(sp)


library(rgdal)
library(sf)

#install.packages("plotKML")
library(plotKML)
library(knitr)
library(png)

library(readxl)


library(ggmap)
library(maps)
library(mapdata)

library(raster)
#library(hms) Add these before I use them?
#library(plyr)

library(formattable)
library(ggpubr)
```

## Location of the trial

Block boundaries drawn in Google earth.



**Aim of trial:**

Selective grazing to barley paddock.
The aim was to evenly graze the frost effected part of the paddock.

Start date: 07/10/2021 3:59:00 PM (record not sure if it is local time)

End date: 20/10/2021 8:54:00 AM (deactivation record not sure if it is local time)

Number of animals: 40 (including one bull)

Date of fence move according to Rick records:



| vp_name	        | boundary_id| boundary_created	| activation_name                        |
| ----------------| -----------|----------------   |----------------------------------------|
| VP01 (Training)	| 2557	     | 7/10/2021 3:59 PM | Oct-07-1629-ACTIVATION-VP01 (Training) |
| VP02	          | 2556       |	11/10/2021 12:23 PM |	Oct-11-1253-ACTIVATION-VP02         |
| VP03            |	0853       |	12/10/2021 8:53 AM  |	Oct-12-0853-ACTIVATION-VP03         |
| VP03 with backgraze|1527     |	14/10/2021 2:57 PM  |	Oct-14-1527-ACTIVATION-VP03 with Backgraze|
| VP03-2 Final    |	1801       |	14/10/2021 5:31 PM | Oct-14-1801-ACTIVATION-VP03-2 Final |
| VP03-2 Final    |	1035       |	15/10/2021 10:05 AM| Oct-15-1035-ACTIVATION-VP03-2 Final |
| VP03-2 Final    |	1520       |	15/10/2021 2:50 PM | Oct-15-1520-ACTIVATION-VP03-2 Final |
| VP04-1 Move     | 0927       |	17/10/2021 9:27 AM | Oct-17-0927-ACTIVATION-VP04-1 Move  |

Some of these fences seem to be almost the same.



The location of the VF were supplied by Gallagher:

| vp_name	        | boundary_id| boundary_created| activation_name                          |
| ----------------| -----------|---------------- |----------------------------------------  |
| VP01 (Training)	| 2557	     | 	7/10/2021 5:11 | Oct-07-1629-ACTIVATION-VP01 (Training)   |
| VP02	          | 2556	     | 	7/10/2021 5:11 | Oct-11-1253-ACTIVATION-VP02              |
| VP03           	| 2561	     | 	7/10/2021 5:19 | Oct-12-0853-ACTIVATION-VP03              |
| VP03-2 Final    | 2590	     | 	14/10/2021 6:59| Oct-14-1801-ACTIVATION-VP03-2 Final      |
| VP03-2 Final    | 2590	     | 	14/10/2021 6:59| Oct-15-1035-ACTIVATION-VP03-2 Final      |
| VP03-2 Final    | 2590	     | 	14/10/2021 6:59| Oct-15-1520-ACTIVATION-VP03-2 Final      |
| VP04-1 Move	    | 2584	     | 	14/10/2021 4:40| Oct-17-0927-ACTIVATION-VP04-1 Move       |



This looks like an error with date and time.
I have emailed Gallagher to confirm.
Also requesting if they have a file to convert the different bounadry_id.

I have also asked for the water tank information.
Rick has given me two collar number:

0491508
0490705


I don't have any records of these collar or any extra collar data that is not already assigned to an animal.


I have used 

- VP 01
- VP 02
- VP 03
- VP 04-1

```{r location of trial, echo=FALSE, message=FALSE, warning=FALSE}

include_graphics("W:/VF/Pinnaroo/activation_VF/VF_boundary_details.png")

```




# Biomass 

Biomass survey was taken using Crop Circle ACS-430 and Crop Circle Phenom (ACS-430 with DAS43X, Holland Scientific, Lincoln, NE, USA).

These were calibrated by field measures of biomass.
 

## Biomass field measures

Biomass measured were taken before and after the trial was run.

Dates: 06/10/2021 and 20/10/2021




```{r biomass pre and post_trial, echo=FALSE, message=FALSE, warning=FALSE}
pre_post_trial_biomass <- read.csv("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/extract_grid_pts_pre_trial.csv")
#select only the pre trial data pts.
#names(pre_post_trial_biomass)

biomass_ave_pre_post <- pre_post_trial_biomass %>% 
  group_by(timing) %>% 
  summarise(av_BM = mean(BM__kg___H, na.rm= FALSE ),
            st_dev = sd(BM__kg___H, na.rm= FALSE),
            count = n())

datatable(biomass_ave_pre_post,
          options = list(dom = 't'),#removes the search bar
          caption = 'Biomass measures kg /Ha.',
          rownames = FALSE,
          colnames = c('Timing', 'Av Biomass', 'St dev biomass', 'Count')) %>% 
  formatRound(c(2:3), 0)
```


# Biomass survey 

**Pre trial survey**

Crop circle and Phenom survey undertaken by Damian on 06/10/2021

**Post trial survey**

Crop circle and Phenom survey undertaken by Damian on 20/10/2021



**Raw data**

Pre Trial

- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Pre trial\raw_data`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Pre trial\raw_data`

Post Trial

- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Post trial\raw_data`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Post trial\raw_data`

Note the files are merged before kriging 

The Phenom the data is split into sensor 1 and 2.

We have only used sensor 1 for this analysis.

We have used NDVI, LAI and DIST, there are other signals / channels that can be use.

At Long Plains we didn't used DIST - perhaps we should?

**Rasters** 

CC Pre Trial 

- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Pre trial\CC_NDVI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Pre trial\CC_LAI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Pre trial\CC_DIST\Vesper`

CC Post Trial

- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Post trial\CC_post_trial_NDVI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Post trial\CC_post_trial_LAI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\CC files\Post trial\CC_post_trial_DIST\Vesper`



Phenom Pre Trial

- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Pre trial\Phenom_Pre_NDVI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Pre trial\Phenom_Pre_LAI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Pre trial\Phenom_Pre_DIST\Vesper`

Phenom Post Trial

- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Post trial\Phenom_post_trial_NDVI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Post trial\Phenom_post_trial_LAI\Vesper`
- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Biomass_data_maps\Phenom files\Post trial\Phenom_post_trial_DIST\Vesper`



Data processing done by Jackie using the following settings:

- Block boundaries created in Google earth pro.

- Data cleaned and trimmed using PAT QGIS tools, standard default settings used


- Block grid of 2m pixel made

- Vesper used for kriging cleaned data

- Vesper setting include; block kriging with a block size of 10m

- Data in below map is displayed as quantile.




## Pre trial maps

```{r cc_and phenom pre_trial, echo=FALSE, message=FALSE, warning=FALSE}

include_graphics("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/Pre_trial_biomass.png")


```


## plot of biomass vs survey data pre trial

Linear model 




```{r pre_trial biomass vs biomass survey, echo=FALSE, message=FALSE, warning=FALSE}

pre_post_trial_biomass <- read.csv("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/extract_grid_pts_pre_trial.csv")
#select only the pre trial data pts.
#names(pre_post_trial_biomass)
#rename some clm this is the order that was extered when extrcated in Arcmap
pre_post_trial_biomass <- pre_post_trial_biomass %>% 
  rename(Survey_Phen_DIST = pre_trial_,
         Survey_Phen_LAI = pre_trial1,
         Survey_Phen_NDVI = pre_tria_1,
         Survey_CC_DIST = cc_all_Hig,
         Survey_CC_LAI = CC_HighDen,
         Survey_CC_NDVI = CC_HighD_1)


#### how does the biomass pre trial relate to the pre trial biomass survey data?
pre_trial_biomass <- pre_post_trial_biomass %>% 
  filter(timing == "pre_trial")


#let rearragne the data so I can do a facet wrap
pre_trial_biomass_long <- pre_trial_biomass %>% 
pivot_longer(cols = starts_with("Survey"),
             names_to = "survey_type",
             values_to = "value")

#pre_trial_biomass_long %>%  group_by(survey_type) %>%  summarise(count = n()) #22

#http://www.sthda.com/english/wiki/ggplot2-scatter-plots-quick-start-guide-r-software-and-data-visualization
# method : smoothing method to be used. Possible values are lm, glm, gam, loess, rlm.
# method = “loess”: This is the default value for small number of observations. It computes a smooth local regression. You can read more about loess using the R code ?loess.
# method =“lm”: It fits a linear model. Note that, it’s also possible to indicate the formula as formula = y ~ poly(x, 3) to specify a degree 3 polynomial.
# se : logical value. If TRUE, confidence interval is displayed around smooth.
# fullrange : logical value. If TRUE, the fit spans the full range of the plot
# level : level of confidence interval to use. Default value is 0.95

plot1 <- pre_trial_biomass_long %>%
  #filter(survey_type == "Survey_CC_NDVI") %>% 
  ggplot(aes(x = value  , y =  BM__kg___H)) +
  geom_point()+
  geom_smooth(mapping = aes(x = value  , y =  BM__kg___H,group = survey_type),
              method = lm, se = FALSE)+
  #geom_smooth(se = FALSE)+
  facet_wrap(.~survey_type, scales = "free_x")+
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90))+
  labs(
    x = paste0("survey data"),
    y = "biomass cuts kg / ha",
    title = "Pre trial data"
  )
plot1
```




## The fit of models biomass vs survey data pre trial




```{r pre_trial biomass vs biomass survey model fit1, echo=FALSE, message=FALSE, warning=FALSE}



#http://www.sthda.com/english/articles/40-regression-analysis/167-simple-linear-regression-in-r/
  
  

pre_trial_biomass_long_CC_NDVI_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_CC_NDVI")
pre_trial_biomass_long_CC_LAI_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_CC_LAI")
pre_trial_biomass_long_CC_DIST_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_CC_DIST")

pre_trial_biomass_long_Phen_NDVI_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_NDVI")
pre_trial_biomass_long_Phen_LAI_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_LAI")
pre_trial_biomass_long_Phen_DIST_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_DIST")



cor_pre_CC_NDVI <- cor(pre_trial_biomass_long_CC_NDVI_pre$value, 
                       pre_trial_biomass_long_CC_NDVI_pre$BM__kg___H)
cor_pre_CC_LAI <- cor(pre_trial_biomass_long_CC_LAI_pre$value, 
                      pre_trial_biomass_long_CC_LAI_pre$BM__kg___H)
cor_pre_CC_DIST <- cor(pre_trial_biomass_long_CC_DIST_pre$value, 
                       pre_trial_biomass_long_CC_DIST_pre$BM__kg___H) 

cor_pre_Phen_NDVI <- cor(pre_trial_biomass_long_Phen_NDVI_pre$value, 
                       pre_trial_biomass_long_Phen_NDVI_pre$BM__kg___H)
cor_pre_Phen_LAI <- cor(pre_trial_biomass_long_Phen_LAI_pre$value, 
                      pre_trial_biomass_long_Phen_LAI_pre$BM__kg___H)
cor_pre_Phen_DIST <- cor(pre_trial_biomass_long_Phen_DIST_pre$value, 
                       pre_trial_biomass_long_Phen_DIST_pre$BM__kg___H) 


#Make a table with the analysis correlation table

pre_trial_table <- data.frame(survey  = c("NDVI", "LAI", "DIST", "NDVI", "LAI", "DIST"),
                              survey_type  = c("Crop Circle", "Crop Circle", "Crop Circle", "Phenom","Phenom","Phenom" ),
                              correlation = c(cor_pre_CC_NDVI, cor_pre_CC_LAI, cor_pre_CC_DIST,cor_pre_Phen_NDVI, cor_pre_Phen_LAI, cor_pre_Phen_DIST ),
                              timing  = c("pre_trial", "pre_trial", "pre_trial", "pre_trial", "pre_trial", "pre_trial"))



model_pre_CC_NDVI <- summary(lm(BM__kg___H ~ value, 
                                data = pre_trial_biomass_long_CC_NDVI_pre))
model_pre_CC_LAI <- summary(lm(BM__kg___H ~ value, 
                               data = pre_trial_biomass_long_CC_LAI_pre))
model_pre_CC_DIST <- summary(lm(BM__kg___H ~ value, 
                                data = pre_trial_biomass_long_CC_DIST_pre))

model_pre_Phen_NDVI <- summary(lm(BM__kg___H ~ value, 
                                data = pre_trial_biomass_long_Phen_NDVI_pre))
model_pre_Phen_LAI <- summary(lm(BM__kg___H ~ value, 
                               data = pre_trial_biomass_long_Phen_LAI_pre))
model_pre_Phen_DIST <- summary(lm(BM__kg___H ~ value, 
                                data = pre_trial_biomass_long_Phen_DIST_pre))

# model_pre_CC_NDVI
# model_pre_CC_NDVI$coefficients[1,1] #b0 Intercept
# model_pre_CC_NDVI$coefficients[2,1] #b1 slope
# model_pre_CC_NDVI$sigma #(Residual Standard Error from Linear Regression Model)
# model_pre_CC_NDVI$adj.r.squared
# model_pre_CC_NDVI$r.squared

#add this info to the pre_trial_table

pre_trial_model_table <- data.frame(survey  = c("NDVI", "LAI", "DIST", "NDVI", "LAI", "DIST"),
                                    survey_type  = c("Crop Circle", "Crop Circle", "Crop Circle", "Phenom","Phenom","Phenom" ),
                                    
                                    Intercept = c(model_pre_CC_NDVI$coefficients[1,1], model_pre_CC_LAI$coefficients[1,1], model_pre_CC_DIST$coefficients[1,1],
                                                  model_pre_Phen_NDVI$coefficients[1,1], model_pre_Phen_LAI$coefficients[1,1], model_pre_Phen_DIST$coefficients[1,1]),
                                    
                                    Slope = c(model_pre_CC_NDVI$coefficients[2,1], model_pre_CC_LAI$coefficients[2,1], model_pre_CC_DIST$coefficients[2,1],
                                              model_pre_Phen_NDVI$coefficients[2,1], model_pre_Phen_LAI$coefficients[2,1], model_pre_Phen_DIST$coefficients[2,1]),
                                    
                                    RSE = c(model_pre_CC_NDVI$sigma, model_pre_CC_LAI$sigma, model_pre_CC_DIST$sigma,
                                            model_pre_Phen_NDVI$sigma, model_pre_Phen_LAI$sigma, model_pre_Phen_DIST$sigma),
                                    
                                    R_Square = c(model_pre_CC_NDVI$r.squared, model_pre_CC_LAI$r.squared, model_pre_CC_DIST$r.squared,
                                                 model_pre_Phen_NDVI$r.squared, model_pre_Phen_LAI$r.squared, model_pre_Phen_DIST$r.squared),
                                    
                                    Adj_R_Square = c(model_pre_CC_NDVI$adj.r.squared, model_pre_CC_LAI$adj.r.squared,model_pre_CC_DIST$adj.r.squared,
                                                     model_pre_Phen_NDVI$adj.r.squared, model_pre_Phen_LAI$adj.r.squared,model_pre_Phen_DIST$adj.r.squared)
)




pre_trial_model <- left_join(pre_trial_table, pre_trial_model_table)

pre_trial_model <- pre_trial_model[, c(4, 1, 2, 3, 5,6,7,8)]

datatable(pre_trial_model,
          options = list(dom = 't'),#removes the search bar
          caption = 'Details of the models.',
          rownames = FALSE)%>%
           formatRound(c(4,8), 2) %>% 
           formatRound(5:7, 0)

```


The Phenom DIST has the best correlations but the R2 is low 0.32.
With this data set I would be reluctant converting survey data to biomass in Kg per ha.

But I guess if you had to this would look like this:

`summary(lm( BM__kg___H~  value, data = pre_trial_biomass_long_Phen_DIST_pre))`


```{r pre_trial biomass vs biomass survey best model fit, echo=FALSE, message=FALSE, warning=FALSE}
pre_trial_biomass_long_Phen_DIST_pre <- pre_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_DIST")

summary(lm( BM__kg___H~  value, data = pre_trial_biomass_long_Phen_DIST_pre))
```

### Best option for converting survey data to biomass in kg/ha -  PRE TRIAL

biomass = intercept + slope * survey

biomass = -22649.9 + 593.8 * Phenom Dist survey value










## Post trial maps

```{r cc_and phenom post_trial, echo=FALSE, message=FALSE, warning=FALSE}

include_graphics("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/Post_trial_biomass.png")


```


## Plot of biomass vs survey data post trial

```{r post_trial biomass vs biomass survey, echo=FALSE, message=FALSE, warning=FALSE}

pre_post_trial_biomass_all <-
  read.csv(
    "W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/extract_grid_pts_pre_trial_all.csv"
  )
#select only the pre trial data pts.

#select post trial data
post_trial_biomass <- pre_post_trial_biomass_all %>%
  dplyr::select(
    FID,
    timing,
    ID,
    Lat,
    Long,
    BM__kg___H,
    Post_CC_ND,
    Post_CC_LA,
    Post_CC_DI,
    Post_Ph_ND,
    Post_Ph_LA,
    Post_Ph_DI
  )


post_trial_biomass <- post_trial_biomass %>%
  rename(
    Survey_Phen_DIST = Post_Ph_DI,
    Survey_Phen_LAI = Post_Ph_LA,
    Survey_Phen_NDVI = Post_Ph_ND,
    Survey_CC_DIST = Post_CC_DI,
    Survey_CC_LAI = Post_CC_LA,
    Survey_CC_NDVI = Post_CC_ND
  )

post_trial_biomass <- post_trial_biomass %>%
  filter(timing == "post_trial")


#let rearragne the data so I can do a facet wrap
post_trial_biomass_long <- post_trial_biomass %>%
  pivot_longer(cols = starts_with("Survey"),
               names_to = "survey_type",
               values_to = "value")


#post_trial_biomass_long %>%  group_by(survey_type) %>%  summarise(count = n())



#http://www.sthda.com/english/wiki/ggplot2-scatter-plots-quick-start-guide-r-software-and-data-visualization
# method : smoothing method to be used. Possible values are lm, glm, gam, loess, rlm.
# method = “loess”: This is the default value for small number of observations. It computes a smooth local regression. You can read more about loess using the R code ?loess.
# method =“lm”: It fits a linear model. Note that, it’s also possible to indicate the formula as formula = y ~ poly(x, 3) to specify a degree 3 polynomial.
# se : logical value. If TRUE, confidence interval is displayed around smooth.
# fullrange : logical value. If TRUE, the fit spans the full range of the plot
# level : level of confidence interval to use. Default value is 0.95

plot2 <- post_trial_biomass_long %>%
  ggplot(aes(x = value  , y =  BM__kg___H)) +
  geom_point()+
  geom_smooth(mapping = aes(x = value  , y =  BM__kg___H,group = survey_type),
              method = lm, se = FALSE)+
  #geom_smooth(se = FALSE)+
  facet_wrap(.~survey_type, scales = "free_x")+
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90))+
  labs(
    x = paste0("survey data"),
    y = "biomass cuts kg / ha",
    title = "Post trial data"
  )
plot2

post_trial_biomass_long_CC_NDVI_post <- post_trial_biomass_long %>%
  filter(survey_type == "Survey_CC_NDVI")
post_trial_biomass_long_CC_LAI_post <- post_trial_biomass_long %>%
  filter(survey_type == "Survey_CC_LAI")
post_trial_biomass_long_CC_DIST_post <- post_trial_biomass_long %>%
  filter(survey_type == "Survey_CC_DIST")

post_trial_biomass_long_Phen_NDVI_post <-
  post_trial_biomass_long %>%
  filter(survey_type == "Survey_Phen_NDVI")
post_trial_biomass_long_Phen_LAI_post <-
  post_trial_biomass_long %>%
  filter(survey_type == "Survey_Phen_LAI")
post_trial_biomass_long_Phen_DIST_post <-
  post_trial_biomass_long %>%
  filter(survey_type == "Survey_Phen_DIST")



cor_post_CC_NDVI <- cor(
  post_trial_biomass_long_CC_NDVI_post$value,
  post_trial_biomass_long_CC_NDVI_post$BM__kg___H
)
cor_post_CC_LAI <- cor(
  post_trial_biomass_long_CC_LAI_post$value,
  post_trial_biomass_long_CC_LAI_post$BM__kg___H
)
cor_post_CC_DIST <- cor(
  post_trial_biomass_long_CC_DIST_post$value,
  post_trial_biomass_long_CC_DIST_post$BM__kg___H
)

cor_post_Phen_NDVI <-
  cor(
    post_trial_biomass_long_Phen_NDVI_post$value,
    post_trial_biomass_long_Phen_NDVI_post$BM__kg___H
  )
cor_post_Phen_LAI <-
  cor(
    post_trial_biomass_long_Phen_LAI_post$value,
    post_trial_biomass_long_Phen_LAI_post$BM__kg___H
  )
cor_post_Phen_DIST <-
  cor(
    post_trial_biomass_long_Phen_DIST_post$value,
    post_trial_biomass_long_Phen_DIST_post$BM__kg___H
  ) 


#Make a table with the analysis correlation table

post_trial_table <-
  data.frame(
    survey  = c("NDVI", "LAI", "DIST", "NDVI", "LAI", "DIST"),
    survey_type  = c(
      "Crop Circle",
      "Crop Circle",
      "Crop Circle",
      "Phenom",
      "Phenom",
      "Phenom"
    ),
    correlation = c(
      cor_post_CC_NDVI,
      cor_post_CC_LAI,
      cor_post_CC_DIST,
      cor_post_Phen_NDVI,
      cor_post_Phen_LAI,
      cor_post_Phen_DIST
    ),
    timing  = c(
      "post_trial",
      "post_trial",
      "post_trial",
      "post_trial",
      "post_trial",
      "post_trial"
    )
  )



model_post_CC_NDVI <- summary(lm(BM__kg___H ~ value,
                                 data = post_trial_biomass_long_CC_NDVI_post))
model_post_CC_LAI <- summary(lm(BM__kg___H ~ value,
                                data = post_trial_biomass_long_CC_LAI_post))
model_post_CC_DIST <- summary(lm(BM__kg___H ~ value,
                                 data = post_trial_biomass_long_CC_DIST_post))

model_post_Phen_NDVI <- summary(lm(BM__kg___H ~ value,
                                   data = post_trial_biomass_long_Phen_NDVI_post))
model_post_Phen_LAI <- summary(lm(BM__kg___H ~ value,
                                  data = post_trial_biomass_long_Phen_LAI_post))
model_post_Phen_DIST <- summary(lm(BM__kg___H ~ value,
                                   data = post_trial_biomass_long_Phen_DIST_post))

# model_post_CC_NDVI
# model_post_CC_NDVI$coefficients[1,1] #b0 Intercept
# model_post_CC_NDVI$coefficients[2,1] #b1 slope
# model_post_CC_NDVI$sigma #(Residual Standard Error from Linear Regression Model)
# model_post_CC_NDVI$adj.r.squared
# model_post_CC_NDVI$r.squared

#add this info to the post_trial_table

post_trial_model_table <-
  data.frame(
    survey  = c("NDVI", "LAI", "DIST", "NDVI", "LAI", "DIST"),
    survey_type  = c(
      "Crop Circle",
      "Crop Circle",
      "Crop Circle",
      "Phenom",
      "Phenom",
      "Phenom"
    ),
    
    Intercept = c(
      model_post_CC_NDVI$coefficients[1, 1],
      model_post_CC_LAI$coefficients[1, 1],
      model_post_CC_DIST$coefficients[1, 1],
      model_post_Phen_NDVI$coefficients[1, 1],
      model_post_Phen_LAI$coefficients[1, 1],
      model_post_Phen_DIST$coefficients[1, 1]
    ),
    
    Slope = c(
      model_post_CC_NDVI$coefficients[2, 1],
      model_post_CC_LAI$coefficients[2, 1],
      model_post_CC_DIST$coefficients[2, 1],
      model_post_Phen_NDVI$coefficients[2, 1],
      model_post_Phen_LAI$coefficients[2, 1],
      model_post_Phen_DIST$coefficients[2, 1]
    ),
    
    RSE = c(
      model_post_CC_NDVI$sigma,
      model_post_CC_LAI$sigma,
      model_post_CC_DIST$sigma,
      model_post_Phen_NDVI$sigma,
      model_post_Phen_LAI$sigma,
      model_post_Phen_DIST$sigma
    ),
    
    R_Square = c(
      model_post_CC_NDVI$r.squared,
      model_post_CC_LAI$r.squared,
      model_post_CC_DIST$r.squared,
      model_post_Phen_NDVI$r.squared,
      model_post_Phen_LAI$r.squared,
      model_post_Phen_DIST$r.squared
    ),
    
    Adj_R_Square = c(
      model_post_CC_NDVI$adj.r.squared,
      model_post_CC_LAI$adj.r.squared,
      model_post_CC_DIST$adj.r.squared,
      model_post_Phen_NDVI$adj.r.squared,
      model_post_Phen_LAI$adj.r.squared,
      model_post_Phen_DIST$adj.r.squared
    )
  )




post_trial_model <-
  left_join(post_trial_table, post_trial_model_table)

post_trial_model <- post_trial_model[, c(4, 1, 2, 3, 5, 6, 7, 8)]

datatable(
  post_trial_model,
  options = list(dom = 't'),
  #removes the search bar
  caption = 'Details of the models.',
  rownames = FALSE
) %>%
  formatRound(c(4, 8), 2) %>%
  formatRound(5:7, 0)


```

### Best option for converting survey data to biomass in kg/ha -  POST TRIAL

The Phenom DIST has the best correlations but the R2 is low 0.32.
With this data set I would be reluctant converting survey data to biomass in Kg per ha.

But I guess if you had to this would look like this:

`summary(lm( BM__kg___H~  value, data = pre_trial_biomass_long_Phen_DIST_pre))`


```{r post_trial biomass vs biomass survey best model fit, echo=FALSE, message=FALSE, warning=FALSE}
post_trial_biomass_long_Phen_DIST_pre <- post_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_DIST")

summary(lm( BM__kg___H~  value, data = post_trial_biomass_long_Phen_DIST_pre))
```



biomass = intercept + slope * survey

biomass = -23,519 + 609	 * Phenom Dist survey value






### Pre and post grids of biomass

Converted using the values and grids outlined above.

```{r phenom DIST converted to biomass pre post_trial, echo=FALSE, message=FALSE, warning=FALSE}

include_graphics("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/Pre Post_trial_biomass_DIST.png")


```

### Pre and post grids of biomass display the VF area only


```{r converted to biomass pre post_trial with VF, echo=FALSE, message=FALSE, warning=FALSE}

include_graphics("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/Pre Post_trial_biomass_DIST with VF.png")


```


### Notes / observation from the above maps.

- There is a big difference between the biomass pre and post trial.
- Pre trial within the VF there are patches of higher biomass long the hard fence line to the south,
especially in the south eastern corner.
- Also higher biomass in the north west corner.
- Although these relatively higher patches remain in the post trial biomass map.
- The difference map indicates that the patches of high biomass before the trial were the most grazed area of the paddock.
- Along the southern fence line a an area of the paddock the animals are unlikely to receive any cues, as the VF boundaries extend beyond the hard fence.
- Areas of light grazing of note is the small triangle on the northern VF between VF 1 and VF3. 

| Summary Stat for VF area (from .tif files)	        | 
| ------- | ----------|-------------|
| stat    |Pre trial  | Post trail	|
| Min     |3030       | 676	        |
| Max     |9215       | 5299        |	
| Mean    |59356      |2831         |	
| Std Dev |1029       |812	        | 




# Weeds data
samples collected 2/11/2021 (Damian)


```{r converted to biomass post_trial with VF and broome data, echo=FALSE, message=FALSE, warning=FALSE}

include_graphics("W:/VF/Pinnaroo/Biomass_data_maps/Pinnaroo_maps/Broome sampling with VF.png")


```

### Notes / observation from the above maps.

- larger patches of Broome in VF 4 and outside VF area
- Brome patches are located in the southern area

- On averages the patches are smaller patches outside VF
- but same number of plants per patch inside and outside the VF

- More heads per viable/plant outside VF.

- less heads on ground and less brome plants on the ground outside VF.



| Summary Stat Brome samples 	        | 
| ------- | ----------|-------------|
| Stats                           |Inside VF  | Outside VF	|
| sum of size of all patches      |10.4       | 7.8	        |
| Average of size of patches      |2.1        | 1.6	        |
| count of patches                |5          | 5           |	
| Average plants per patch        |35         |35.6         |	
| Average HM heads are viable/plant |40.5     |46.8         |
| Average heads on ground         |22.2       |16.2         |
| Average brome plants on ground  |4.9       |0         |



- `W:\VF\Pinnaroo\Biomass_data_maps\Pre and Post trial biomass\Pinnaroo Pre_Post Biomass cuts.xlsx`




## Background information on animal collar data from Gallagher


**Contact**

The chief data scientist/ data analytics manager is:


Dr. Shiva Pratap Gopakumar | Data Scientist | eShepherd

Gallagher eShepherd Pty Ltd

1100-1102 Toorak Road, Camberwell, VIC, 3124

DDI +61 3 8849 8600 | MOB +61 426 092 143

EMAIL shiva.gopakumar@gallagher.com | WEB www.gallagher.com



**Data provided**


Every 10 mins generates a new row of data.

This can be viewed from the timeOfEvent column.

**timeOfEvent**

Note that this timeOfEvent has a date and time stamp which is in GMT.

The *timeOfEvent* will need to be converted to local time.

Which is 10.5 hrs difference 

(during daylight saving starts 3rd Oct - so this is correct for our dataset)

**GPS**

The GPS data is a snapshot of the location of the animals in a 10 min window.

Data columns that are supplied:

- *gpsData.lat*	
- *gpsData.lng*


I will use the lat and long column to create a location of the animal in the 10 min window.

The accuracy of this reading can be viewed within this 10 min window.


In other years we have calculated the velocity but I am not sure if we need this now and how would it work?

I am also not sure about the use of the velocity reading, how would this be calculated if only one GPS record was logged every 10mins? 


**Stimuli - cue and audio readings**

The *cumulativeAudioCount* and	*cumulativeShockCount* columns are a running total of how many stimuli the animal has received since the start of the trial, and is re calculated every 10 mins.

It appears that the increments are not reset when a new fence is implement.
Instead its just keeps cumulating.

**Device details**

The *deviceName* is the name of the collar, more details about the mob can be found on the shared drive.


- `\\FSSA2-ADL\clw-share1\Microlab\VF\Pinnaroo\Animal_wts\Usable animal weights.xlsx`
- tab merged_dataID_wts

There is another columns which has information about the device this is called *deviceUIDHex*.




**Virtual Fence**


There is a column which is called *minDistanceToIZ*, which is the distance of the animal to the VF.

I am not sure if this is the min distance the animal got to the fence in the 10 min window or its the distance calculated from the logged GPS point in the file in the 10 mins window.

If it is the min distance the animal got to and not just the distance from the fence in the 'snap shot' this would be useful.

Column called *fencesID* is the name of the fence.




       

If the *fencesID* is NULL then the *minDistanceToIZ* is also NULL.

If the *fencesID* is blank then the *minDistanceToIZ* is also NULL or has a value there are only 2 of these.


*"If the values in “fenceID” column as blank, this means there is no active virtual fence for that neckband yet. Therefore, if you are performing some analysis related to virtual fencing, you can ignore those rows with blank fenceIDs."*


**Animal activity**

There are 3 columns that relate to the 

- *resting%*	

- *moving%*

- *grazing%* 



The first 3 should add up to 100% and this is a sum value for the 10 min of time.

For example in the 10 min window the animals has spent 37% of the time resting, 30% moving and 33% grazing.









# Data manipulation 


## Step 1 bring in the raw data and set date and time formats


**Add date column**

- this is has no rounding and is just the date extracted from the local time column

**retain data within a date and time range**

- I have also filter out data within a date and time range (I have got this from Rick notes)

- between "2021-10-07 16:03:00" to "2020-10-20 08:54:00" localtime 











```{r bring in the data, message=TRUE, include=FALSE}

animal_GPS_data <- read_csv("W:/VF/Pinnaroo/animal behaviour data/raw_data/CSIRO_Pinnaroo.csv", 
                                              col_types = cols(timeOfEvent = col_datetime(format = "%d/%m/%Y %H:%M")))

animal_GPS_data <- animal_GPS_data %>% 
  mutate(GMT = ymd_hms(timeOfEvent, tz = "GMT"))

animal_GPS_data <- animal_GPS_data %>% 
  mutate(local_time = with_tz(GMT, tz = "Australia/Adelaide"))

animal_GPS_data <- animal_GPS_data %>% 
  dplyr::select(deviceUIDHex:grazing_percentage, GMT:local_time)

animal_GPS_data <- animal_GPS_data %>%  filter(local_time >= ymd_hms("2021-10-07 16:03:00", tz= "Australia/Adelaide"), 
                         local_time <=  ymd_hms("2021-10-20 08:54:00", tz= "Australia/Adelaide"))

animal_GPS_data <- animal_GPS_data %>% 
  mutate(date = as.Date(local_time, tz= "Australia/Adelaide"),
         DOY = yday(date))



```

**Column for VF area**

- Create a column that will help identify what part of the paddock the cows are allowed to graze in.

- Gallagher will confirm the fenceID in the animal movement file and the fenceID boundary file (as they have different codes) 

- The animal movement data has an clm with 'fence ID', so when a VF is active this clm will have the fence ID value in it.

- There is a problem with some logged points, the fence ID clm is blank.
- I assume this is happening because the VF is deactivated.
- Gallagher suggested "For the VF dataset only retaining data points that have an associated fence ID".




- The list below is the dates and times for the fences ID in the animal movement files.


```{r fence ID date and time, echo=FALSE}

check2 <- animal_GPS_data %>% group_by(  fencesID) %>% 
  summarise(min_local_time = ymd_hms(min(local_time), tz= "Australia/Adelaide"),
            max_local_time = ymd_hms(max(local_time), tz= "Australia/Adelaide"),
            count_records = n())
check2 <- arrange(check2, min_local_time)

check2

# the DT table seems to use some strange time setting not sure what the work around is other than date only as below
# DT::datatable(
#   check2,
#   options = list(dom = 't'),
#   #removes the search bar
#   caption = 'Details of the fence ID.',
#   rownames = FALSE
# ) %>% 
#   formatDate(c(2,3), method = 'toDateString')


```

- the fenceID (from the animal movement file) need to be matched up with the VF area (the spatial data)




*This needs confirming and if needs changing the code below need work*


| fence ID in GPS data 	                | 
| ----------          |-------------    |
|   ID in GPS data    | ID for mapping	|
|   165 +02           | 	VP01          |
|   165               | 	VP01          |
|   1f6da             |   VF02          |
|   1d10b             | 	VP03          |
|   1f076             | 	VP03_2        |
|   1ab95             | 	VP03_2        |
|   1df99             | 	VF04          |
|   NULL              | 	?             |



**Add Day since start of VF columns** 



- Add extra one for days since fence move clm called 'day_since_vf_start'

- Julian days from local date/time column and then subtract start of VF.


VF Area 1 = date 2021-10-07 16:03:00
VF Area 2 = date 2021-10-11 12:33:00
VF Area 3 = date 2021-10-12 09:03:00 (this is a few fences all named VF3 )
VF Area 4 = date 2021-10-17 09:33:00


```{r add clms days since start, echo=FALSE, message=FALSE, warning=FALSE}

## clm for day of year in local time

vf1_area_start  <-  yday(ymd_hms("2021-10-07 16:03:00", tz= "Australia/Adelaide")) 
vf2_area_start  <-  yday(ymd_hms("2021-10-11 12:33:00", tz= "Australia/Adelaide"))
vf3_area_start  <-  yday(ymd_hms("2021-10-12 09:03:00", tz= "Australia/Adelaide"))
vf4_area_start  <-  yday(ymd_hms("2021-10-17 09:33:00", tz= "Australia/Adelaide"))


animal_GPS_data <- animal_GPS_data %>%  
  mutate(
    VF_area  = case_when(
      fencesID == "1.65E+02" ~ "VF_area1",
      fencesID == "165" ~ "VF_area1",
      
      fencesID == "1f6da" ~ "VF_area2",
      
      fencesID == "1d10b" ~ "VF_area3",
      fencesID == "1f076" ~ "VF_area3",
      fencesID == "1ab95" ~ "VF_area3",
      
      fencesID == "1df99" ~ "VF_area4"))


animal_GPS_data <- animal_GPS_data %>%  
  mutate(
    day_since_vf_start  = case_when(
      VF_area == "VF_area1" ~ (DOY-vf1_area_start)+1,
      
      VF_area == "VF_area2" ~ (DOY-vf2_area_start)+1,
      
      VF_area == "VF_area3" ~ (DOY-vf3_area_start)+1,
      
      VF_area == "VF_area4" ~ (DOY-vf4_area_start)+1))
  

check3 <- animal_GPS_data %>% group_by( VF_area) %>% 
  summarise('min day since VF move' = min(day_since_vf_start),
            'max day since VF move' = max(day_since_vf_start))

check3
```
##### Check numbers

```{r check 5pm data, echo=TRUE, message=FALSE, warning=FALSE}
animal_count

```


## 1. Animal weights



```{r animal wts, echo=FALSE, message=FALSE, warning=FALSE}
animal_wts <- read_excel("W:/VF/Pinnaroo/Animal_wts/Usable animal weights.xlsx", sheet ="merged_dataID_wts" )



animal_wts <- animal_wts %>%
  dplyr::select(deviceUIDHex,
                deviceName,
                date_in = "Date weight in",
                date_out ="date weight out",
                wt_diff ="Weight difference")


animal_wts <- animal_wts %>%
  filter(!is.na(deviceName))
#animal_wts$date_out - animal_wts$date_in

animal_wts <- animal_wts %>%
  mutate(wt_diff_daily = wt_diff /13)

animal_wts_stats <- animal_wts %>% 
  group_by() %>% 
  summarise(sum_wt_gain = sum(wt_diff, na.rm = TRUE),
            std_dev_wt_gain = sd(wt_diff, na.rm = TRUE),
            wt_gain_SE = std_dev_wt_gain / sqrt(n()),
            
            Av_wt_diff_daily = mean(wt_diff_daily, na.rm = TRUE),
            std_dev_daily_gain = sd(wt_diff_daily, na.rm = TRUE),
            wt_daily_gain_SE = std_dev_daily_gain / sqrt(n()),
            
            count = n())
  
animal_wts_stats

# datatable(
#   animal_wts_stats,
#   options = list(dom = 't'),
#   #removes the search bar
#   caption = 'Weight gain kg',
#   rownames = FALSE,
#   colnames = c('Total for mob', 'Average per animal', 'Stdev per animal', 'Av per animal per day',"SE",'Count') )%>%
#     formatRound(c(1:5), 2)

```


```{r animal wts plot, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(animal_wts, aes(as.factor(deviceName), wt_diff)) +
  geom_col()+
  theme_bw()+
  theme(axis.text.x=element_blank(),
  axis.ticks = element_blank())+
  labs(title="Animal weight gain after 13 days",
       x ="Animal", y = "Weight gain (kg)")
```


## 2. audio/pulse

Dana / Caroline: For the audio/pulse, we think just an average proportion in the text included SE would be sufficient rather than any graphs. Could this be the proportion of audio cues relative to total signals? We are anticipating it would be around 0.8. (No stats analyses, just the values)


prop audio total cues =
max_cumulativeAudioCount/(max_cumulativeShockCount + max_cumulativeAudioCount) *100

The below table is the mean of the proportion, audio and pluse and the standard error.

mean proportion of audio cues as a total of all cues  = xx% SE xx





```{r number of cues, message=FALSE, warning=FALSE, include=FALSE}

#1 create an ID for each row
str(animal_GPS_data)

# just select the last day of the trial?

min(animal_GPS_data$local_time)
max_time_to_filter <- animal_GPS_data %>%  group_by(deviceName) %>% 
  summarise(max_local_time = max(local_time, na.rm =TRUE))
# View(max_time_to_filter)
# count(max_time_to_filter)

max_time_to_filter2 <- max_time_to_filter %>%  group_by( ) %>% 
  summarise(min_max_time = min(max_local_time, na.rm =TRUE))
#View(max_time_to_filter2)

max_time_to_filter2

## roungly pic a window of time around the max time
last_record <- animal_GPS_data %>% 
  filter(between(ymd_hms(local_time),
                 ymd_hms("2021-10-20 08:00:00"), ymd_hms("2021-10-20 08:53:00"))) 

#View(last_record)
#Do we have one reading per animal? 
check <- last_record %>% group_by(deviceName) %>% 
  summarise(count = n())
#check
#yes we have one reading per animal
#now do we have 39 animals?

check2 <- unique(check$deviceName)
#print(check2) # yes 39
#names(last_record)
last_record <- last_record %>% 
  dplyr::select(deviceUIDHex:timeOfEvent,cumulativeAudioCount, cumulativeShockCount, local_time, DOY )
#str(last_record)

last_record_summary <- last_record %>% 
  mutate(prop_audio_to_cues = cumulativeAudioCount/ (cumulativeShockCount + cumulativeAudioCount)*100)
#View(last_record_summary)

last_record_summary_stats <- last_record_summary %>% 
  group_by( ) %>% 
  summarise(Av_Audio = mean(cumulativeAudioCount, na.rm = TRUE),
            std_dev_Av_Audio = sd(cumulativeAudioCount, na.rm = TRUE),
            SE_Av_Audio = std_dev_Av_Audio / sqrt(n()),
            
            Av_Pulse = mean(cumulativeShockCount, na.rm = TRUE),
            std_dev_Av_Pulse = sd(cumulativeShockCount, na.rm = TRUE),
            SE_Av_Pulse = std_dev_Av_Pulse / sqrt(n()),
            
            Av_prop = mean(prop_audio_to_cues, na.rm = TRUE),
            std_dev_prop = sd(prop_audio_to_cues, na.rm = TRUE),
            SE_Av_prop = std_dev_prop / sqrt(n()),
            
            count = n())

last_record_summary_stats

```





```{r number of cues, echo=FALSE, message=FALSE, warning=FALSE}

last_record_summary_stats %>% dplyr::select( `Av Audio` =Av_Audio, `SE Audio` = SE_Av_Audio,
                                             `Av Pulse` = Av_Pulse, `SE Pulse` = SE_Av_Pulse,
                                             `Av prop` = Av_prop, `SE prop` = SE_Av_prop, count) %>% 
  
  mutate(across(where(is.numeric), ~ round(., digits = 2))) %>% 
   formattable()

```


### 3. Behaviors

Dana / Caroline: We like the plot of grazing/resting/moving across all animals together (so not the individual animal plots). Probably no stats analyses because the unit is the group and we only have 1 group. But, could you include mean % values for each behavior (+SE) for the first 3 days for each group AND mean total values (+SE) for the group across the trial (just as values to include in the text). We would refer to it in
the discussion, we anticipate if there are substantial differences, it would be in the first few days. 


Jackie: 
- I have cal the average time spent resting, moving, grazing per animal per day (mean per animal per day).
- Then using this dataset I have cal the mean, SD ,SE for each activity and group (the mean across all animals for whole trial).



The three days are the 21-10 to 23-10.


```{r write up behaviours, message=FALSE, warning=FALSE, include=FALSE}

str(animal_GPS_data)

animal_GPS_data$resting_percentage <- as.double(animal_GPS_data$resting_percentage)
animal_GPS_data$moving_percentage  <- as.double(animal_GPS_data$moving_percentage )
animal_GPS_data$grazing_percentage   <- as.double(animal_GPS_data$grazing_percentage  )

week1_2_3_animal_per_day_activity <- animal_GPS_data %>% group_by(date, deviceName) %>% 
  summarise(av_resting = mean( resting_percentage, na.rm = TRUE),
            av_moving = mean( moving_percentage, na.rm = TRUE),
            av_grazing = mean( grazing_percentage, na.rm = TRUE))



week1_2_3_animal_per_day_activity <- pivot_longer(week1_2_3_animal_per_day_activity,
                                                  cols = c("av_resting", "av_moving", "av_grazing"),
                                                  names_to = "activity")






week1_2_3_activity <- week1_2_3_animal_per_day_activity %>% 
  group_by(activity)%>%
  summarise(activity_mean = mean(value, na.rm = TRUE),
            activity_SD =sd(value,  na.rm =TRUE),
            activity_SE=activity_SD/sqrt(n()))

week1_2_3_activity <- week1_2_3_activity %>% 
  mutate( activity = case_when(
    activity == "av_grazing" ~ "grazing",
    activity == "av_moving" ~ "moving",
    activity == "av_resting" ~ "resting"
  ))




week1_2_3_activity
#using summary data per animal per day per group per activity 
#"week1_2_3_animal_per_day_activity"
#I have extracting the first 3 days 
# Activation of VF 1 	2021-10-07  to the 	2021-10-10
str(animal_GPS_data)


time_check <- animal_GPS_data %>% group_by( VF_area) %>% 
  summarise(min_local_time = ymd_hms(min(local_time), tz= "Australia/Adelaide"),
            max_local_time = ymd_hms(max(local_time), tz= "Australia/Adelaide")) %>% 
  arrange(min_local_time)

week1_2_3_animal_per_day_activity <- ungroup(week1_2_3_animal_per_day_activity)
week1_2_3_animal_per_day_activity_3days <-
  week1_2_3_animal_per_day_activity %>% 
  filter(between(date, 
                 as.Date("2021-10-07"), as.Date("2021-10-10")))

min(week1_2_3_animal_per_day_activity_3days$date)                
max(week1_2_3_animal_per_day_activity_3days$date)               


str(week1_2_3_animal_per_day_activity_3days)
activity_sum_3days <- week1_2_3_animal_per_day_activity_3days %>% 
  group_by(activity)%>%
  summarise(activity_mean_3days = mean(value, na.rm = TRUE),
            activity_SD_3days =sd(value,  na.rm =TRUE),
            activity_SE_3days=activity_SD_3days/sqrt(n()))


activity_sum_3days <- activity_sum_3days %>% 
  mutate( activity = case_when(
    activity == "av_grazing" ~ "grazing 3days",
    activity == "av_moving" ~ "moving 3days",
    activity == "av_resting" ~ "resting 3days"
  ))
activity_sum_3days <- activity_sum_3days %>% 
  rename(activity_mean = activity_mean_3days,
         activity_SE = activity_SE_3days) %>% 
  dplyr::select(activity,
                activity_mean,
                activity_SE)

################################################################################
week1_2_3_animal_per_day_activity_3days_onwards <-
  week1_2_3_animal_per_day_activity %>% 
  filter(date > as.Date("2021-10-10"))


min(week1_2_3_animal_per_day_activity_3days_onwards$date)                
max(week1_2_3_animal_per_day_activity_3days_onwards$date)               


str(week1_2_3_animal_per_day_activity_3days_onwards)
activity_sum_3days_onwards <- week1_2_3_animal_per_day_activity_3days_onwards %>% 
  group_by(activity)%>%
  summarise(activity_mean_3days_onwards = mean(value, na.rm = TRUE),
            activity_SD_3days_onwards =sd(value,  na.rm =TRUE),
            activity_SE_3days_onwards=activity_SD_3days_onwards/sqrt(n()))


activity_sum_3days_onwards <- activity_sum_3days_onwards %>% 
  mutate( activity = case_when(
    activity == "av_grazing" ~ "grazing excluding first 3days",
    activity == "av_moving" ~ "moving excluding first 3days",
    activity == "av_resting" ~ "resting excluding first 3days"
  ))
activity_sum_3days_onwards <- activity_sum_3days_onwards %>% 
  rename(activity_mean = activity_mean_3days_onwards,
         activity_SE = activity_SE_3days_onwards) %>% 
  dplyr::select(activity,
                activity_mean,
                activity_SE)


activity_sum_3days_onwards
activity_sum_3days 

activity_summary <- rbind(activity_sum_3days,activity_sum_3days_onwards )
activity_summary
activity_summary <- activity_summary %>%  arrange(activity )

################# results

activity_summary <- activity_summary %>% 
  mutate(time_period = case_when(
    activity == "grazing excluding first 3days" ~ "full trial",
    activity == "moving excluding first 3days" ~ "full trial",
    activity == "resting excluding first 3days" ~ "full trial",
    
    activity == "grazing 3days" ~ "3 days",
    activity == "resting 3days" ~ "3 days",
    activity == "moving 3days" ~ "3 days"
  ))


activity_summary <- activity_summary %>% 
  mutate(activity_type = case_when(
    activity == "grazing excluding first 3days" ~ "grazing",
    activity == "moving excluding first 3days" ~ "moving",
    activity == "resting excluding first 3days" ~ "resting",
    
    activity == "grazing 3days" ~ "grazing",
    activity == "resting 3days" ~ "resting",
    activity == "moving 3days" ~ "moving"
  ))

activity_summary

activity_summary %>%
  ggplot(aes(x = time_period , y = activity_mean, fill = time_period)) +
  geom_col()+
  scale_fill_manual(values = c("grey", "grey50"))+
  theme_classic() +
  facet_wrap(.~ factor(activity_type, levels=c('resting','grazing','moving')))+
  geom_errorbar(position=position_dodge(.9), width=.25, aes(ymin=activity_mean-activity_SE, ymax=activity_mean+activity_SE)) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x=element_blank())+
  labs(
    x = "VF Mob",
    y = "% time attributed to activity")

```





```{r write up behaviours results2, echo=FALSE, message=FALSE, warning=FALSE}
week1_2_3_activity %>% 
 mutate(across(where(is.numeric), ~ round(., digits = 2))) %>% 
   formattable()



```





#### Behaviors on first 3 days vs the rest of the trial.

First three days are 07/10 to 10/10
Excluding the first three days are 11/10 to 20/10.

```{r write up behaviours test 3 days vs full trial, echo=FALSE, message=FALSE, warning=FALSE}
#Add another clm for time periods



activity_summary %>%
  ggplot(aes(x = time_period , y = activity_mean, fill = time_period)) +
  geom_col()+
  scale_fill_manual(values = c("grey", "grey50"))+
  theme_classic() +
  facet_wrap(.~ factor(activity_type, levels=c('resting','grazing','moving')))+
  geom_errorbar(position=position_dodge(.9), width=.25, aes(ymin=activity_mean-activity_SE, ymax=activity_mean+activity_SE)) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x=element_blank())+
  labs(
    x = "VF Mob",
    y = "% time attributed to activity")
```

Table of above

```{r write up behaviours results 3 days, echo=FALSE, message=FALSE, warning=FALSE}

activity_summary %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2))) %>% 
  formattable()


```





```{r write up behaviours test 3 days vs full trial t test, echo=FALSE, message=FALSE, warning=FALSE}



animal_GPS_data$resting_percentage <- as.double(animal_GPS_data$resting_percentage)
animal_GPS_data$moving_percentage  <- as.double(animal_GPS_data$moving_percentage )
animal_GPS_data$grazing_percentage   <- as.double(animal_GPS_data$grazing_percentage  )

first_days_behaviour_test <- animal_GPS_data %>% group_by(date, deviceName) %>% 
  summarise(av_resting = mean( resting_percentage, na.rm = TRUE),
            av_moving = mean( moving_percentage, na.rm = TRUE),
            av_grazing = mean( grazing_percentage, na.rm = TRUE))





first_days_behaviour_test <- ungroup(first_days_behaviour_test)
### split into two groups 
first_days_behaviour_test_1 <- first_days_behaviour_test %>% 
  filter(between(date, 
                 as.Date("2021-10-07"), as.Date("2021-10-10"))) %>% 
                 mutate(time_period = "first_3_days")

first_days_behaviour_test_2 <- first_days_behaviour_test %>% 
  filter(date > as.Date("2021-10-10"))%>% 
  mutate(time_period = "exclude_first_3_days")

# min(first_days_behaviour_test_1$date)                
# max(first_days_behaviour_test_1$date)
# 
# min(first_days_behaviour_test_2$date)                
# max(first_days_behaviour_test_2$date)               

first_days_behaviour_test_1_2 <- rbind(first_days_behaviour_test_1,first_days_behaviour_test_2 )
#str(first_days_behaviour_test_1_2)

## resting for on VF

t.test_resting_first_days <-compare_means(av_resting ~ time_period,  data = first_days_behaviour_test_1_2, 
                                          method = "t.test")

t.test_grazing_first_days <-compare_means(av_grazing ~ time_period,  data = first_days_behaviour_test_1_2, 
                                          method = "t.test")
t.test_moving_first_days <-compare_means(av_moving ~ time_period,  data = first_days_behaviour_test_1_2, 
                                         method = "t.test")


t_test_behaviour_first_days <- rbind(t.test_resting_first_days,t.test_grazing_first_days,t.test_moving_first_days)
#t_test_behaviour
t_test_behaviour_first_days %>% 
  #mutate(across(where(is.numeric), ~ round(., digits = 10))) %>% 
  formattable()

```

  
  
  
### 4. GPS plots

Dana / Caroline: For GPS Plots. Could you plot the movement of each group on the first day of fence activation/deactivation. 

These would be plots similar to the ones you have done ‘Days since start of VF’ in the document but would only include day 1 of each activation/deactivation and would have the control group plotted simultaneously. 

Thus, 4 paddock map plots in total. (Let me know if that is unclear and/or if Rick has something different in mind). 

Is it also possible to calculate the time from fence change until the first animal entered the new, previously excluded area? 

That way we could state ‘on average, once a fence had shifted position/was deactivated, it took the animals 2 (?) hours to move into the new area’. 





  
## Extra Notes
  
-  Track which animal spent time outside the VF and ID them, non compliant.
-  Compare early behaviour (the behaviour in the first couple of days) of these of these non compliant vs main herd.
-  The numbers should be approx 30/40 main herd, 10/40 or 6-7/40 were non compliant.
-  Note at time Heath re oriented these non compliant animals (back into the VF area).

-  Can we identify hotspots outside the VF area, if so do they match anything in the biomass data?
-  Exclude the Bull from the start.



  